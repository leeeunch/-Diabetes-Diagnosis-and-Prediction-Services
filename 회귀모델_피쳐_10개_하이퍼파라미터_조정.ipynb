{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "oRPAcZZuYEoc",
        "rfmAWSM8YNK6"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 드라이브 마운트"
      ],
      "metadata": {
        "id": "KIe-b3fvXobe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e80D7zx05-2a",
        "outputId": "7ca995b0-47b6-4aaf-f231-6ac8a76a44cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 라이브러리 호출 및 데이터 로드"
      ],
      "metadata": {
        "id": "4Vxxtu6ZXr8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#라이브러리 호출\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow.keras import layers \n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.layers import Dense, Input, Dropout, BatchNormalization"
      ],
      "metadata": {
        "id": "Y2d7eoWc6JWc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/MyDrive/은찬/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBNqgvJe6uB5",
        "outputId": "04982c6e-24b8-4b49-e6b7-479865d89e76"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/은찬\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('PPG_data (1).csv')"
      ],
      "metadata": {
        "id": "EZuUzwy965T6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['Unnamed: 11'], axis=1)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "j5_ssIH37Gjd",
        "outputId": "564da141-75f7-462b-dd16-8149bcf009a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      HR   HRV    SDNN   RMSSD   PNN50      VLF        LF        HF  gender  \\\n",
              "0     82   142  61.633  90.972  0.5738  289.552    954.31   1128.05       0   \n",
              "1     73   309  61.633  90.972  0.5738  289.552    954.31   1128.05       0   \n",
              "2     79    48  61.633  90.972  0.5738  289.552    954.31   1128.05       0   \n",
              "3     83   370  61.633  90.972  0.5738  289.552    954.31   1128.05       0   \n",
              "4     97    -1  61.633  90.972  0.5738  289.552    954.31   1128.05       0   \n",
              "...   ..   ...     ...     ...     ...      ...       ...       ...     ...   \n",
              "5335  17 -3097  52.724  81.000  0.5902  865.406  14215.90  68600.80       0   \n",
              "5336  57  2427  52.724  81.000  0.5902  865.406  14215.90  68600.80       0   \n",
              "5337  78   993  52.724  81.000  0.5902  865.406  14215.90  68600.80       0   \n",
              "5338  91  1172  52.724  81.000  0.5902  865.406  14215.90  68600.80       0   \n",
              "5339  94    21  52.724  81.000  0.5902  865.406  14215.90  68600.80       0   \n",
              "\n",
              "      age  blood_sugar  \n",
              "0      57          183  \n",
              "1      57          183  \n",
              "2      57          183  \n",
              "3      57          183  \n",
              "4      57          183  \n",
              "...   ...          ...  \n",
              "5335   19          125  \n",
              "5336   19          125  \n",
              "5337   19          125  \n",
              "5338   19          125  \n",
              "5339   19          125  \n",
              "\n",
              "[5340 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76fccb51-ee86-49ad-b56d-cd6a1287f17a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HR</th>\n",
              "      <th>HRV</th>\n",
              "      <th>SDNN</th>\n",
              "      <th>RMSSD</th>\n",
              "      <th>PNN50</th>\n",
              "      <th>VLF</th>\n",
              "      <th>LF</th>\n",
              "      <th>HF</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>blood_sugar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>82</td>\n",
              "      <td>142</td>\n",
              "      <td>61.633</td>\n",
              "      <td>90.972</td>\n",
              "      <td>0.5738</td>\n",
              "      <td>289.552</td>\n",
              "      <td>954.31</td>\n",
              "      <td>1128.05</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>73</td>\n",
              "      <td>309</td>\n",
              "      <td>61.633</td>\n",
              "      <td>90.972</td>\n",
              "      <td>0.5738</td>\n",
              "      <td>289.552</td>\n",
              "      <td>954.31</td>\n",
              "      <td>1128.05</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>79</td>\n",
              "      <td>48</td>\n",
              "      <td>61.633</td>\n",
              "      <td>90.972</td>\n",
              "      <td>0.5738</td>\n",
              "      <td>289.552</td>\n",
              "      <td>954.31</td>\n",
              "      <td>1128.05</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>83</td>\n",
              "      <td>370</td>\n",
              "      <td>61.633</td>\n",
              "      <td>90.972</td>\n",
              "      <td>0.5738</td>\n",
              "      <td>289.552</td>\n",
              "      <td>954.31</td>\n",
              "      <td>1128.05</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>97</td>\n",
              "      <td>-1</td>\n",
              "      <td>61.633</td>\n",
              "      <td>90.972</td>\n",
              "      <td>0.5738</td>\n",
              "      <td>289.552</td>\n",
              "      <td>954.31</td>\n",
              "      <td>1128.05</td>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5335</th>\n",
              "      <td>17</td>\n",
              "      <td>-3097</td>\n",
              "      <td>52.724</td>\n",
              "      <td>81.000</td>\n",
              "      <td>0.5902</td>\n",
              "      <td>865.406</td>\n",
              "      <td>14215.90</td>\n",
              "      <td>68600.80</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5336</th>\n",
              "      <td>57</td>\n",
              "      <td>2427</td>\n",
              "      <td>52.724</td>\n",
              "      <td>81.000</td>\n",
              "      <td>0.5902</td>\n",
              "      <td>865.406</td>\n",
              "      <td>14215.90</td>\n",
              "      <td>68600.80</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5337</th>\n",
              "      <td>78</td>\n",
              "      <td>993</td>\n",
              "      <td>52.724</td>\n",
              "      <td>81.000</td>\n",
              "      <td>0.5902</td>\n",
              "      <td>865.406</td>\n",
              "      <td>14215.90</td>\n",
              "      <td>68600.80</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5338</th>\n",
              "      <td>91</td>\n",
              "      <td>1172</td>\n",
              "      <td>52.724</td>\n",
              "      <td>81.000</td>\n",
              "      <td>0.5902</td>\n",
              "      <td>865.406</td>\n",
              "      <td>14215.90</td>\n",
              "      <td>68600.80</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5339</th>\n",
              "      <td>94</td>\n",
              "      <td>21</td>\n",
              "      <td>52.724</td>\n",
              "      <td>81.000</td>\n",
              "      <td>0.5902</td>\n",
              "      <td>865.406</td>\n",
              "      <td>14215.90</td>\n",
              "      <td>68600.80</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "      <td>125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5340 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76fccb51-ee86-49ad-b56d-cd6a1287f17a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-76fccb51-ee86-49ad-b56d-cd6a1287f17a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-76fccb51-ee86-49ad-b56d-cd6a1287f17a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train-test split"
      ],
      "metadata": {
        "id": "tZ9oenKEXv7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blood_sugar_rate_lr = df\n",
        "x_lr = blood_sugar_rate_lr[['HR', 'HRV', 'SDNN', 'RMSSD', 'PNN50', 'VLF', 'LF', 'HF', 'gender','age']]              # x축에 input 데이터 나열\n",
        "y_lr = blood_sugar_rate_lr[['blood_sugar']]              # y축에 타겟 데이터 나열\n",
        "\n",
        "x_train_lr, x_test_lr, y_train_lr, y_test_lr = \\\n",
        "  train_test_split(x_lr, y_lr, stratify=y_lr, test_size=0.2, random_state=42)      # 훈련 데이터와 테스트 데이터 분류\n",
        "\n",
        "x_train_lr1, x_val_lr, y_train_lr1, y_val_lr = \\\n",
        "  train_test_split(x_train_lr, y_train_lr, stratify=y_train_lr, \\\n",
        "                   test_size=0.2, random_state=42)                     # 훈련 데이터와 검증 데이터 분류          \n",
        " \n",
        "scaler_lr = StandardScaler()   # 객체 만들기\n",
        "scaler_lr.fit(x_train_lr1)     # 변환 규칙을 익히기\n",
        "x_train_scaled_lr = scaler_lr.transform(x_train_lr1)  # 데이터를 표준화 전처리\n",
        "x_test_scaled_lr = scaler_lr.transform(x_test_lr)\n",
        "x_val_scaled_lr = scaler_lr.transform(x_val_lr)      # 데이터를 표준화 전처리"
      ],
      "metadata": {
        "id": "nSr3cRRX7Mma"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 구축"
      ],
      "metadata": {
        "id": "k5fC0T3s_A1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regularizer=tf.keras.regularizers.l2(0.01)\n",
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=10, activation='relu', kernel_regularizer=regularizer))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1, activation='linear'))\n",
        "sgd = tf.keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.1, nesterov=True)\n",
        "adam = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer=adam, metrics=['mae'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPByiP8H_Fya",
        "outputId": "b56ef2fb-ed10-4f98-f260-377a675cef51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n",
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MAE, MSE, RMSE "
      ],
      "metadata": {
        "id": "zqc8MjluZI9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_scale = m_best_11.predict(x_test_scaled_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfiGLRoIZmlN",
        "outputId": "21c7049e-0df9-4330-b428-c99c9500d90c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 0s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(y_test_lr, y_pred_scale)\n",
        "mse = mean_squared_error(y_test_lr, y_pred_scale)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_lr, y_pred_scale))\n",
        "\n",
        "print('MAE: {0:.2f}'.format(mae))\n",
        "print('MSE: {0:.2f}'.format(mse))\n",
        "print('RMSE: {0:.2f}'.format(rmse)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yMz_kT6ZNOK",
        "outputId": "73434977-1b52-44e4-d61a-7dec080583a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 4.02\n",
            "MSE: 29.08\n",
            "RMSE: 5.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습"
      ],
      "metadata": {
        "id": "posrmWsA-uZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## epoch : 100"
      ],
      "metadata": {
        "id": "yMiQhU4b-lzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('best-model_regress_1210_3.h5',   #ModelCheckpoint의 객체 #'best-model.h5'이름으로 저장\n",
        "                                                save_best_only=True) #모델이 \"최상\"으로 간주될 때만 저장\n",
        "hist_1208_3 = model.fit(\n",
        "    x_train_scaled_lr , y_train_lr1.values,\n",
        "    batch_size=32,\n",
        "    epochs=100,\n",
        "    validation_data=(x_val_scaled_lr, y_val_lr.values),\n",
        "    callbacks=[checkpoint_cb],\n",
        "    verbose=1)"
      ],
      "metadata": {
        "id": "R1DDg3g0kTgN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "237bbba1-a8b1-437d-9d7e-84ccff9e54d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 141.0581 - mae: 8.3851 - val_loss: 460.5086 - val_mae: 6.7074\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 130.6326 - mae: 8.0667 - val_loss: 448.1657 - val_mae: 6.4238\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 131.0506 - mae: 7.9429 - val_loss: 451.2507 - val_mae: 6.5018\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 126.1048 - mae: 7.9759 - val_loss: 468.3661 - val_mae: 6.4975\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 153.9005 - mae: 8.2983 - val_loss: 469.0474 - val_mae: 7.0098\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 148.1517 - mae: 8.5997 - val_loss: 468.7733 - val_mae: 7.2744\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 142.1049 - mae: 8.2064 - val_loss: 472.5044 - val_mae: 7.3394\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 5s 50ms/step - loss: 160.4671 - mae: 8.3574 - val_loss: 488.8443 - val_mae: 7.2996\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 129.0624 - mae: 8.0521 - val_loss: 497.9812 - val_mae: 7.2844\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 151.0806 - mae: 8.3428 - val_loss: 513.0714 - val_mae: 7.2192\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 140.3851 - mae: 8.0844 - val_loss: 501.0739 - val_mae: 7.2380\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 158.5051 - mae: 8.2310 - val_loss: 506.4887 - val_mae: 7.1883\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 148.2890 - mae: 8.2396 - val_loss: 492.0509 - val_mae: 7.1584\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 141.4445 - mae: 8.0474 - val_loss: 523.9910 - val_mae: 7.0199\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 145.4681 - mae: 8.3797 - val_loss: 530.5792 - val_mae: 7.5211\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 131.2697 - mae: 8.2245 - val_loss: 534.6041 - val_mae: 7.2249\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 127.8264 - mae: 7.9603 - val_loss: 501.6966 - val_mae: 7.2966\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 131.6806 - mae: 8.1536 - val_loss: 473.9014 - val_mae: 7.0967\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 6s 59ms/step - loss: 151.8407 - mae: 8.2647 - val_loss: 462.8815 - val_mae: 6.8357\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 127.7803 - mae: 8.0287 - val_loss: 476.0473 - val_mae: 6.8968\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 132.4243 - mae: 8.1730 - val_loss: 497.5006 - val_mae: 7.1917\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 112.7496 - mae: 7.8259 - val_loss: 489.3895 - val_mae: 6.9437\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 124.7562 - mae: 8.1481 - val_loss: 507.7485 - val_mae: 7.4945\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 133.1796 - mae: 8.0179 - val_loss: 466.3087 - val_mae: 6.6935\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 119.1155 - mae: 7.9780 - val_loss: 448.3554 - val_mae: 6.4302\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 137.8712 - mae: 8.2129 - val_loss: 475.2420 - val_mae: 6.8337\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 146.7188 - mae: 8.0860 - val_loss: 525.6809 - val_mae: 6.9415\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 122.0006 - mae: 7.7654 - val_loss: 517.6492 - val_mae: 7.0274\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 129.4440 - mae: 8.0323 - val_loss: 559.9868 - val_mae: 7.2170\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 131.5455 - mae: 8.1671 - val_loss: 577.5084 - val_mae: 7.1890\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 154.5922 - mae: 8.2158 - val_loss: 617.7108 - val_mae: 7.2028\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 3s 30ms/step - loss: 121.6105 - mae: 7.7828 - val_loss: 661.9374 - val_mae: 7.0767\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 135.0117 - mae: 7.9863 - val_loss: 628.7991 - val_mae: 7.0906\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 155.1964 - mae: 8.2449 - val_loss: 589.0818 - val_mae: 6.7875\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 125.3167 - mae: 7.8328 - val_loss: 577.7961 - val_mae: 6.9603\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 150.6447 - mae: 8.2248 - val_loss: 585.4508 - val_mae: 7.1204\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 118.9628 - mae: 7.7759 - val_loss: 607.7802 - val_mae: 7.3970\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 223.9103 - mae: 8.8235 - val_loss: 587.4105 - val_mae: 7.9503\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 155.7998 - mae: 8.4049 - val_loss: 626.0529 - val_mae: 7.7335\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 3s 33ms/step - loss: 148.7434 - mae: 8.4558 - val_loss: 680.3792 - val_mae: 7.7304\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 131.3593 - mae: 7.9958 - val_loss: 643.4339 - val_mae: 7.8366\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 127.7352 - mae: 8.2084 - val_loss: 595.6355 - val_mae: 7.8468\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 125.5022 - mae: 8.0674 - val_loss: 610.6213 - val_mae: 7.7547\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 133.1240 - mae: 8.1561 - val_loss: 575.0758 - val_mae: 7.3990\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 120.0048 - mae: 7.9592 - val_loss: 620.5012 - val_mae: 7.4478\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 135.6385 - mae: 8.1275 - val_loss: 611.5173 - val_mae: 7.4868\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 120.8113 - mae: 8.0425 - val_loss: 574.3065 - val_mae: 6.9523\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 116.7387 - mae: 7.7767 - val_loss: 549.1398 - val_mae: 7.1235\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 136.1260 - mae: 8.1699 - val_loss: 579.6315 - val_mae: 7.2604\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 129.1340 - mae: 8.0000 - val_loss: 511.0022 - val_mae: 6.9938\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 123.4383 - mae: 7.9536 - val_loss: 499.0039 - val_mae: 6.8762\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 142.4470 - mae: 8.2765 - val_loss: 556.3657 - val_mae: 7.5213\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 127.3957 - mae: 8.1004 - val_loss: 617.4592 - val_mae: 7.7997\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 119.7246 - mae: 8.0394 - val_loss: 573.3007 - val_mae: 7.4364\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 148.1606 - mae: 8.5554 - val_loss: 600.2921 - val_mae: 7.7465\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 135.3317 - mae: 8.0028 - val_loss: 553.0221 - val_mae: 7.5192\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 132.6047 - mae: 8.2223 - val_loss: 498.0754 - val_mae: 6.8653\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 128.6328 - mae: 8.0071 - val_loss: 493.7812 - val_mae: 6.7354\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 3s 33ms/step - loss: 130.9709 - mae: 7.9387 - val_loss: 517.5670 - val_mae: 6.9133\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 150.2116 - mae: 8.3512 - val_loss: 560.5314 - val_mae: 6.9271\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 115.4546 - mae: 7.7031 - val_loss: 558.9888 - val_mae: 7.1976\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 140.8025 - mae: 8.0907 - val_loss: 555.5884 - val_mae: 7.4301\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 128.0878 - mae: 7.9237 - val_loss: 571.7205 - val_mae: 7.4441\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 160.3420 - mae: 8.6366 - val_loss: 563.7218 - val_mae: 7.6965\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 155.2237 - mae: 8.3700 - val_loss: 624.8089 - val_mae: 7.8252\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 170.3740 - mae: 8.5880 - val_loss: 567.4241 - val_mae: 7.8537\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 168.9759 - mae: 8.4867 - val_loss: 594.1805 - val_mae: 8.1676\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 155.5770 - mae: 8.4201 - val_loss: 498.1150 - val_mae: 7.5766\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 152.0489 - mae: 8.5977 - val_loss: 483.4166 - val_mae: 7.0415\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 140.8142 - mae: 8.1634 - val_loss: 507.4898 - val_mae: 7.1548\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 132.8436 - mae: 8.2682 - val_loss: 565.9659 - val_mae: 7.0968\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 135.3664 - mae: 8.2587 - val_loss: 651.8876 - val_mae: 7.4215\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 147.6339 - mae: 8.3981 - val_loss: 736.9286 - val_mae: 7.6189\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 118.2924 - mae: 7.9293 - val_loss: 643.3798 - val_mae: 7.7543\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 136.4441 - mae: 8.0845 - val_loss: 823.4152 - val_mae: 8.1620\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 158.0739 - mae: 8.6262 - val_loss: 666.3024 - val_mae: 7.5463\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 167.2122 - mae: 8.3935 - val_loss: 542.4403 - val_mae: 7.0624\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 133.6187 - mae: 8.3976 - val_loss: 458.5603 - val_mae: 7.0209\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 147.2177 - mae: 8.2835 - val_loss: 481.3159 - val_mae: 6.8255\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 128.0011 - mae: 7.9181 - val_loss: 452.3848 - val_mae: 6.6876\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 129.0909 - mae: 8.0245 - val_loss: 438.0531 - val_mae: 6.8416\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 137.1456 - mae: 7.9738 - val_loss: 312.0295 - val_mae: 6.4445\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 168.1282 - mae: 8.5970 - val_loss: 455.2969 - val_mae: 7.0977\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 148.3237 - mae: 8.1731 - val_loss: 442.8204 - val_mae: 6.7420\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 127.8762 - mae: 7.9121 - val_loss: 445.9663 - val_mae: 6.8466\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 143.5523 - mae: 8.4295 - val_loss: 451.6634 - val_mae: 6.9113\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 3s 33ms/step - loss: 117.4205 - mae: 7.7348 - val_loss: 447.9719 - val_mae: 6.7356\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 173.6075 - mae: 8.3384 - val_loss: 466.0712 - val_mae: 6.3505\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 126.3706 - mae: 7.9845 - val_loss: 489.0966 - val_mae: 6.8349\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 127.1096 - mae: 8.0936 - val_loss: 464.9466 - val_mae: 6.7339\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 158.9171 - mae: 8.3911 - val_loss: 450.9570 - val_mae: 6.8598\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 131.8106 - mae: 7.9454 - val_loss: 445.7032 - val_mae: 6.7773\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 151.7320 - mae: 8.3509 - val_loss: 445.8271 - val_mae: 6.7450\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 140.8095 - mae: 8.0546 - val_loss: 449.2785 - val_mae: 6.3740\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 160.4180 - mae: 8.4440 - val_loss: 463.3370 - val_mae: 7.2462\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 134.5147 - mae: 8.1383 - val_loss: 435.2193 - val_mae: 6.5240\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 129.7981 - mae: 8.2826 - val_loss: 446.5304 - val_mae: 6.5790\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 126.5919 - mae: 7.9796 - val_loss: 433.5271 - val_mae: 6.6511\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 125.1170 - mae: 7.9159 - val_loss: 442.1951 - val_mae: 6.4532\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 149.9946 - mae: 8.2542 - val_loss: 456.7677 - val_mae: 6.1950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m_best_11 = keras.models.load_model(\"best-model_regress_1210_3.h5\")"
      ],
      "metadata": {
        "id": "VbLRUfYdAj-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = r2_score(y_test_lr.values, m_best_11.predict(x_test_scaled_lr))\n",
        "print(r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhUtMoFXAgFz",
        "outputId": "2ff82bdb-44c2-4022-e469-9cde1026a06e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 1s 8ms/step\n",
            "0.6463230069321357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## eposh : 1000"
      ],
      "metadata": {
        "id": "fJyG332H-hoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#best model 저장\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('best-model_regress_1208_8.h5',   #ModelCheckpoint의 객체 #'best-model.h5'이름으로 저장\n",
        "                                                save_best_only=True) #모델이 \"최상\"으로 간주될 때만 저장\n",
        "hist_1208_3 = model.fit(\n",
        "    x_train_scaled_lr , y_train_lr1.values,\n",
        "    batch_size=32,\n",
        "    epochs=1000,\n",
        "    validation_data=(x_val_scaled_lr, y_val_lr.values),\n",
        "    callbacks=[checkpoint_cb],\n",
        "    verbose=1)"
      ],
      "metadata": {
        "id": "qOwCt3-6kpa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a038cba-44f9-4817-ca18-c67ae6e02b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "107/107 [==============================] - 15s 49ms/step - loss: 15027.7148 - mae: 118.9663 - val_loss: 14995.7852 - val_mae: 118.9007\n",
            "Epoch 2/1000\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 14543.6680 - mae: 117.0547 - val_loss: 16420.2520 - val_mae: 125.6417\n",
            "Epoch 3/1000\n",
            "107/107 [==============================] - 6s 56ms/step - loss: 13632.7021 - mae: 113.4104 - val_loss: 15249.7969 - val_mae: 121.5040\n",
            "Epoch 4/1000\n",
            "107/107 [==============================] - 5s 50ms/step - loss: 12356.3584 - mae: 107.9803 - val_loss: 11759.0615 - val_mae: 106.6922\n",
            "Epoch 5/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 10861.7070 - mae: 101.0173 - val_loss: 10201.9570 - val_mae: 96.7790\n",
            "Epoch 6/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 9233.3008 - mae: 92.7396 - val_loss: 7705.4297 - val_mae: 84.9490\n",
            "Epoch 7/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 7546.0151 - mae: 83.4691 - val_loss: 6782.8618 - val_mae: 80.5776\n",
            "Epoch 8/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 5966.6973 - mae: 73.4694 - val_loss: 5474.6182 - val_mae: 72.6312\n",
            "Epoch 9/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 4565.4146 - mae: 63.2844 - val_loss: 4380.4497 - val_mae: 63.3266\n",
            "Epoch 10/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 3323.4158 - mae: 53.2060 - val_loss: 3303.5203 - val_mae: 53.0040\n",
            "Epoch 11/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 2349.9470 - mae: 43.5111 - val_loss: 2874.1890 - val_mae: 43.6514\n",
            "Epoch 12/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 1628.4498 - mae: 34.6948 - val_loss: 6435.9609 - val_mae: 41.5956\n",
            "Epoch 13/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 1191.0735 - mae: 27.7232 - val_loss: 4773.9272 - val_mae: 29.5059\n",
            "Epoch 14/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 827.0314 - mae: 21.4814 - val_loss: 5139.8970 - val_mae: 25.1885\n",
            "Epoch 15/1000\n",
            "107/107 [==============================] - 3s 30ms/step - loss: 624.6830 - mae: 17.5690 - val_loss: 3411.2476 - val_mae: 21.3855\n",
            "Epoch 16/1000\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 570.4228 - mae: 15.9171 - val_loss: 2603.7815 - val_mae: 19.6742\n",
            "Epoch 17/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 464.9348 - mae: 14.6271 - val_loss: 4611.5762 - val_mae: 19.9645\n",
            "Epoch 18/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 509.5215 - mae: 14.6167 - val_loss: 4407.6177 - val_mae: 17.6594\n",
            "Epoch 19/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 439.5104 - mae: 14.1701 - val_loss: 11717.7119 - val_mae: 23.3301\n",
            "Epoch 20/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 402.5300 - mae: 13.9702 - val_loss: 2614.5371 - val_mae: 15.2598\n",
            "Epoch 21/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 447.6866 - mae: 14.1595 - val_loss: 9358.8086 - val_mae: 20.9667\n",
            "Epoch 22/1000\n",
            "107/107 [==============================] - 3s 33ms/step - loss: 418.9137 - mae: 14.0427 - val_loss: 6474.4976 - val_mae: 18.9062\n",
            "Epoch 23/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 389.1724 - mae: 13.7295 - val_loss: 7623.5410 - val_mae: 20.5076\n",
            "Epoch 24/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 373.4626 - mae: 13.4222 - val_loss: 15097.7998 - val_mae: 25.4312\n",
            "Epoch 25/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 404.9596 - mae: 13.9665 - val_loss: 16581.6055 - val_mae: 26.9529\n",
            "Epoch 26/1000\n",
            "107/107 [==============================] - 6s 59ms/step - loss: 375.5530 - mae: 13.2318 - val_loss: 6772.0825 - val_mae: 19.2253\n",
            "Epoch 27/1000\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 377.4533 - mae: 13.5669 - val_loss: 13693.5742 - val_mae: 24.8589\n",
            "Epoch 28/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 341.3022 - mae: 13.2758 - val_loss: 9456.0664 - val_mae: 21.5563\n",
            "Epoch 29/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 374.8018 - mae: 13.4851 - val_loss: 5544.3145 - val_mae: 17.9695\n",
            "Epoch 30/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 388.5154 - mae: 13.4838 - val_loss: 4851.3130 - val_mae: 17.1424\n",
            "Epoch 31/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 350.5868 - mae: 13.0419 - val_loss: 20029.7500 - val_mae: 28.7342\n",
            "Epoch 32/1000\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 344.1426 - mae: 13.1207 - val_loss: 9028.3467 - val_mae: 21.7139\n",
            "Epoch 33/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 381.2074 - mae: 13.5563 - val_loss: 9808.8789 - val_mae: 20.6817\n",
            "Epoch 34/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 425.6813 - mae: 13.7884 - val_loss: 1334.5454 - val_mae: 12.7872\n",
            "Epoch 35/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 372.3273 - mae: 13.3154 - val_loss: 13926.9014 - val_mae: 23.8547\n",
            "Epoch 36/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 357.9724 - mae: 13.3322 - val_loss: 11440.4609 - val_mae: 22.2844\n",
            "Epoch 37/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 315.5177 - mae: 12.7660 - val_loss: 11098.3633 - val_mae: 22.6456\n",
            "Epoch 38/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 339.1648 - mae: 12.9935 - val_loss: 12328.5098 - val_mae: 24.1589\n",
            "Epoch 39/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 300.6821 - mae: 12.8289 - val_loss: 23400.4336 - val_mae: 29.7223\n",
            "Epoch 40/1000\n",
            "107/107 [==============================] - 6s 57ms/step - loss: 367.0125 - mae: 13.1053 - val_loss: 19313.3125 - val_mae: 27.5418\n",
            "Epoch 41/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 360.6420 - mae: 13.2763 - val_loss: 5990.1030 - val_mae: 17.6198\n",
            "Epoch 42/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 405.2871 - mae: 13.4449 - val_loss: 26149.0449 - val_mae: 29.9303\n",
            "Epoch 43/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 349.4187 - mae: 13.1612 - val_loss: 15149.3984 - val_mae: 24.5740\n",
            "Epoch 44/1000\n",
            "107/107 [==============================] - 6s 56ms/step - loss: 341.9812 - mae: 13.1064 - val_loss: 15718.0967 - val_mae: 25.0476\n",
            "Epoch 45/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 314.6858 - mae: 12.6279 - val_loss: 11235.7197 - val_mae: 22.1767\n",
            "Epoch 46/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 323.2410 - mae: 12.7435 - val_loss: 24383.2148 - val_mae: 29.7570\n",
            "Epoch 47/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 360.1020 - mae: 13.2920 - val_loss: 7335.2739 - val_mae: 18.7359\n",
            "Epoch 48/1000\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 367.2767 - mae: 12.9702 - val_loss: 15290.6250 - val_mae: 24.7868\n",
            "Epoch 49/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 324.0127 - mae: 12.6854 - val_loss: 12766.8799 - val_mae: 23.2167\n",
            "Epoch 50/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 361.4346 - mae: 13.2216 - val_loss: 17855.9355 - val_mae: 26.5344\n",
            "Epoch 51/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 320.3111 - mae: 12.6927 - val_loss: 24375.7305 - val_mae: 29.7984\n",
            "Epoch 52/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 339.9438 - mae: 12.8773 - val_loss: 22085.3691 - val_mae: 28.5370\n",
            "Epoch 53/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 349.9543 - mae: 12.8378 - val_loss: 9582.0547 - val_mae: 20.4535\n",
            "Epoch 54/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 325.9249 - mae: 12.5021 - val_loss: 20261.5703 - val_mae: 26.9995\n",
            "Epoch 55/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 327.8650 - mae: 12.7617 - val_loss: 15533.1523 - val_mae: 24.8865\n",
            "Epoch 56/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 298.4046 - mae: 12.5347 - val_loss: 27720.3477 - val_mae: 30.0221\n",
            "Epoch 57/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 339.7790 - mae: 12.7081 - val_loss: 70541.5234 - val_mae: 43.6376\n",
            "Epoch 58/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 363.2421 - mae: 12.9806 - val_loss: 19388.0078 - val_mae: 26.2734\n",
            "Epoch 59/1000\n",
            "107/107 [==============================] - 5s 50ms/step - loss: 294.1524 - mae: 12.2432 - val_loss: 26727.3164 - val_mae: 29.2095\n",
            "Epoch 60/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 312.1600 - mae: 12.2517 - val_loss: 28700.7031 - val_mae: 30.2836\n",
            "Epoch 61/1000\n",
            "107/107 [==============================] - 3s 33ms/step - loss: 356.8916 - mae: 12.7290 - val_loss: 39272.6250 - val_mae: 34.5270\n",
            "Epoch 62/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 336.9464 - mae: 12.7369 - val_loss: 54283.5312 - val_mae: 38.8501\n",
            "Epoch 63/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 298.7199 - mae: 12.4070 - val_loss: 17516.5684 - val_mae: 25.1635\n",
            "Epoch 64/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 304.8772 - mae: 12.2552 - val_loss: 24248.9727 - val_mae: 28.6308\n",
            "Epoch 65/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 304.1545 - mae: 12.1394 - val_loss: 16291.4492 - val_mae: 24.3864\n",
            "Epoch 66/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 258.7838 - mae: 11.8889 - val_loss: 15101.5635 - val_mae: 24.1115\n",
            "Epoch 67/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 258.6653 - mae: 11.8011 - val_loss: 12763.8203 - val_mae: 22.6965\n",
            "Epoch 68/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 324.3397 - mae: 12.3337 - val_loss: 41349.5938 - val_mae: 35.1034\n",
            "Epoch 69/1000\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 302.7210 - mae: 12.1093 - val_loss: 21349.9219 - val_mae: 26.4050\n",
            "Epoch 70/1000\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 359.2367 - mae: 12.3209 - val_loss: 28212.6816 - val_mae: 28.9413\n",
            "Epoch 71/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 298.3758 - mae: 12.1544 - val_loss: 34259.9727 - val_mae: 31.1786\n",
            "Epoch 72/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 268.1175 - mae: 11.9425 - val_loss: 43740.2656 - val_mae: 34.8772\n",
            "Epoch 73/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 265.4951 - mae: 11.8187 - val_loss: 48057.8203 - val_mae: 36.1314\n",
            "Epoch 74/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 276.5830 - mae: 11.8706 - val_loss: 38116.6797 - val_mae: 32.2205\n",
            "Epoch 75/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 293.5278 - mae: 12.1877 - val_loss: 108594.8984 - val_mae: 51.0403\n",
            "Epoch 76/1000\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 271.6141 - mae: 11.7673 - val_loss: 28366.1895 - val_mae: 28.6827\n",
            "Epoch 77/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 290.7422 - mae: 11.6530 - val_loss: 9136.1162 - val_mae: 19.0064\n",
            "Epoch 78/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 259.5766 - mae: 11.4853 - val_loss: 27800.1289 - val_mae: 28.7569\n",
            "Epoch 79/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 253.0546 - mae: 11.5688 - val_loss: 50280.0234 - val_mae: 36.7903\n",
            "Epoch 80/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 249.4624 - mae: 11.1703 - val_loss: 46300.3750 - val_mae: 35.2923\n",
            "Epoch 81/1000\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 292.1224 - mae: 11.7829 - val_loss: 47970.4414 - val_mae: 35.2835\n",
            "Epoch 82/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 270.5870 - mae: 11.5853 - val_loss: 20525.1973 - val_mae: 26.0676\n",
            "Epoch 83/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 266.9160 - mae: 11.4463 - val_loss: 44334.8477 - val_mae: 34.6851\n",
            "Epoch 84/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 233.2341 - mae: 10.9948 - val_loss: 24332.8418 - val_mae: 27.2412\n",
            "Epoch 85/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 249.0405 - mae: 11.3949 - val_loss: 72259.0703 - val_mae: 41.7489\n",
            "Epoch 86/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 236.1403 - mae: 11.1483 - val_loss: 70872.2734 - val_mae: 41.4612\n",
            "Epoch 87/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 272.6957 - mae: 11.4332 - val_loss: 48998.9023 - val_mae: 36.2362\n",
            "Epoch 88/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 248.0549 - mae: 11.3313 - val_loss: 32423.0605 - val_mae: 30.3934\n",
            "Epoch 89/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 246.4136 - mae: 11.1670 - val_loss: 27725.4570 - val_mae: 28.4158\n",
            "Epoch 90/1000\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 244.5391 - mae: 11.0670 - val_loss: 54846.5117 - val_mae: 37.4275\n",
            "Epoch 91/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 231.1595 - mae: 10.9378 - val_loss: 51816.6562 - val_mae: 36.3803\n",
            "Epoch 92/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 289.2697 - mae: 11.3709 - val_loss: 16188.2295 - val_mae: 22.9260\n",
            "Epoch 93/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 261.1563 - mae: 11.2311 - val_loss: 41626.1523 - val_mae: 33.3812\n",
            "Epoch 94/1000\n",
            "107/107 [==============================] - 7s 64ms/step - loss: 226.9541 - mae: 10.9556 - val_loss: 44350.0859 - val_mae: 33.7562\n",
            "Epoch 95/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 219.0205 - mae: 10.8407 - val_loss: 39431.6367 - val_mae: 32.4403\n",
            "Epoch 96/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 247.8941 - mae: 10.8435 - val_loss: 58717.5664 - val_mae: 38.5623\n",
            "Epoch 97/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 300.8174 - mae: 11.3210 - val_loss: 47247.0625 - val_mae: 36.2119\n",
            "Epoch 98/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 236.7326 - mae: 11.1230 - val_loss: 30030.4492 - val_mae: 29.3974\n",
            "Epoch 99/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 264.1668 - mae: 11.0179 - val_loss: 47793.4961 - val_mae: 34.8100\n",
            "Epoch 100/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 212.0512 - mae: 10.6736 - val_loss: 43218.1289 - val_mae: 33.8596\n",
            "Epoch 101/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 255.8981 - mae: 11.0295 - val_loss: 43591.1992 - val_mae: 33.9070\n",
            "Epoch 102/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 214.7329 - mae: 10.7351 - val_loss: 33930.7773 - val_mae: 30.2476\n",
            "Epoch 103/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 249.9277 - mae: 10.8932 - val_loss: 41840.9414 - val_mae: 32.7092\n",
            "Epoch 104/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 248.2409 - mae: 10.9469 - val_loss: 45152.1328 - val_mae: 33.8465\n",
            "Epoch 105/1000\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 235.0097 - mae: 10.7991 - val_loss: 47456.2695 - val_mae: 34.2581\n",
            "Epoch 106/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 296.2526 - mae: 11.2639 - val_loss: 27909.2969 - val_mae: 27.3965\n",
            "Epoch 107/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 254.0459 - mae: 11.1723 - val_loss: 39124.6172 - val_mae: 32.0142\n",
            "Epoch 108/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 223.6229 - mae: 10.6286 - val_loss: 30534.3457 - val_mae: 28.4612\n",
            "Epoch 109/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 248.7140 - mae: 10.9542 - val_loss: 26593.1523 - val_mae: 27.0486\n",
            "Epoch 110/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 267.2948 - mae: 10.9922 - val_loss: 56461.1914 - val_mae: 36.6576\n",
            "Epoch 111/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 223.0185 - mae: 10.8870 - val_loss: 45339.9961 - val_mae: 33.2545\n",
            "Epoch 112/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 194.9420 - mae: 10.5188 - val_loss: 40627.6406 - val_mae: 32.3591\n",
            "Epoch 113/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 220.8913 - mae: 10.6106 - val_loss: 27728.7852 - val_mae: 27.7194\n",
            "Epoch 114/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 256.1398 - mae: 10.9970 - val_loss: 35833.8281 - val_mae: 30.6239\n",
            "Epoch 115/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 227.2562 - mae: 10.6639 - val_loss: 35113.1406 - val_mae: 30.8266\n",
            "Epoch 116/1000\n",
            "107/107 [==============================] - 3s 33ms/step - loss: 220.9252 - mae: 10.3715 - val_loss: 41561.4844 - val_mae: 32.7509\n",
            "Epoch 117/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 222.6282 - mae: 10.5481 - val_loss: 49135.4766 - val_mae: 35.5999\n",
            "Epoch 118/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 222.2071 - mae: 10.8469 - val_loss: 34569.4023 - val_mae: 29.8413\n",
            "Epoch 119/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 215.1226 - mae: 10.5273 - val_loss: 35966.5664 - val_mae: 30.4469\n",
            "Epoch 120/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 218.2374 - mae: 10.4513 - val_loss: 36899.5117 - val_mae: 31.0668\n",
            "Epoch 121/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 260.0894 - mae: 10.9822 - val_loss: 54825.8945 - val_mae: 37.9649\n",
            "Epoch 122/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 259.7183 - mae: 11.4284 - val_loss: 52435.7578 - val_mae: 36.7055\n",
            "Epoch 123/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 245.5170 - mae: 11.1235 - val_loss: 56280.9609 - val_mae: 36.9680\n",
            "Epoch 124/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 230.5335 - mae: 10.3769 - val_loss: 47934.8359 - val_mae: 34.6779\n",
            "Epoch 125/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 254.1755 - mae: 10.9611 - val_loss: 75583.5859 - val_mae: 42.3293\n",
            "Epoch 126/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 266.9857 - mae: 10.9900 - val_loss: 632.3052 - val_mae: 9.0221\n",
            "Epoch 127/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 241.1319 - mae: 10.6173 - val_loss: 64900.2344 - val_mae: 39.3780\n",
            "Epoch 128/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 219.7823 - mae: 10.3907 - val_loss: 48547.9961 - val_mae: 34.6109\n",
            "Epoch 129/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 278.7773 - mae: 10.9799 - val_loss: 284.8634 - val_mae: 9.3990\n",
            "Epoch 130/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 293.2394 - mae: 11.6749 - val_loss: 37288.6914 - val_mae: 31.2712\n",
            "Epoch 131/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 272.7618 - mae: 11.0616 - val_loss: 32968.1562 - val_mae: 29.6401\n",
            "Epoch 132/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 248.3376 - mae: 11.1272 - val_loss: 35182.0781 - val_mae: 30.4519\n",
            "Epoch 133/1000\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 238.1311 - mae: 10.9889 - val_loss: 10956.2900 - val_mae: 19.9911\n",
            "Epoch 134/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 270.6750 - mae: 10.8363 - val_loss: 25092.8301 - val_mae: 26.3807\n",
            "Epoch 135/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 242.0352 - mae: 10.6372 - val_loss: 22114.8496 - val_mae: 25.4036\n",
            "Epoch 136/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 244.4116 - mae: 10.8450 - val_loss: 23465.8418 - val_mae: 26.1726\n",
            "Epoch 137/1000\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 241.8517 - mae: 10.6744 - val_loss: 47370.3711 - val_mae: 34.6071\n",
            "Epoch 138/1000\n",
            "107/107 [==============================] - 7s 66ms/step - loss: 245.8733 - mae: 10.5853 - val_loss: 50918.2891 - val_mae: 35.4943\n",
            "Epoch 139/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 238.2917 - mae: 10.7795 - val_loss: 60545.2773 - val_mae: 38.3088\n",
            "Epoch 140/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 195.8063 - mae: 10.3522 - val_loss: 54996.8789 - val_mae: 37.1616\n",
            "Epoch 141/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 244.2398 - mae: 10.6464 - val_loss: 38373.8438 - val_mae: 30.6496\n",
            "Epoch 142/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 251.6402 - mae: 10.6321 - val_loss: 59817.2344 - val_mae: 37.4081\n",
            "Epoch 143/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 233.6381 - mae: 10.6870 - val_loss: 42232.3320 - val_mae: 32.8827\n",
            "Epoch 144/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 225.3451 - mae: 10.7596 - val_loss: 53112.2812 - val_mae: 36.3231\n",
            "Epoch 145/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 248.9225 - mae: 10.7719 - val_loss: 18786.7910 - val_mae: 23.1804\n",
            "Epoch 146/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 281.6851 - mae: 11.1570 - val_loss: 99208.0781 - val_mae: 47.4675\n",
            "Epoch 147/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 264.0527 - mae: 10.9216 - val_loss: 56603.0508 - val_mae: 36.7751\n",
            "Epoch 148/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 255.1249 - mae: 10.8759 - val_loss: 36988.0547 - val_mae: 30.3985\n",
            "Epoch 149/1000\n",
            "107/107 [==============================] - 7s 62ms/step - loss: 214.5556 - mae: 10.4929 - val_loss: 55719.5039 - val_mae: 36.1597\n",
            "Epoch 150/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 258.9550 - mae: 10.9108 - val_loss: 29173.0898 - val_mae: 27.7071\n",
            "Epoch 151/1000\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 206.8281 - mae: 10.4614 - val_loss: 60474.7188 - val_mae: 38.3136\n",
            "Epoch 152/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 221.9797 - mae: 10.3436 - val_loss: 36375.4375 - val_mae: 30.1901\n",
            "Epoch 153/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 216.6194 - mae: 10.3394 - val_loss: 60620.5195 - val_mae: 37.8163\n",
            "Epoch 154/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 200.1775 - mae: 10.1960 - val_loss: 46757.0234 - val_mae: 34.0255\n",
            "Epoch 155/1000\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 207.4032 - mae: 10.3181 - val_loss: 38718.2891 - val_mae: 31.2904\n",
            "Epoch 156/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 209.3257 - mae: 10.2043 - val_loss: 47894.1797 - val_mae: 33.8732\n",
            "Epoch 157/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 236.8148 - mae: 10.7636 - val_loss: 36387.2031 - val_mae: 31.1221\n",
            "Epoch 158/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 256.8466 - mae: 10.7941 - val_loss: 25152.0605 - val_mae: 26.7669\n",
            "Epoch 159/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 249.3016 - mae: 10.6591 - val_loss: 41539.8906 - val_mae: 32.5501\n",
            "Epoch 160/1000\n",
            "107/107 [==============================] - 3s 31ms/step - loss: 254.6106 - mae: 10.5118 - val_loss: 13075.9639 - val_mae: 20.0843\n",
            "Epoch 161/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 209.4714 - mae: 10.4040 - val_loss: 18566.2168 - val_mae: 23.6299\n",
            "Epoch 162/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 221.2897 - mae: 10.5773 - val_loss: 25801.0215 - val_mae: 26.6885\n",
            "Epoch 163/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 228.9213 - mae: 10.5352 - val_loss: 44475.2461 - val_mae: 33.5482\n",
            "Epoch 164/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 204.9507 - mae: 10.1041 - val_loss: 24926.2852 - val_mae: 26.0630\n",
            "Epoch 165/1000\n",
            "107/107 [==============================] - 3s 33ms/step - loss: 224.5191 - mae: 10.4806 - val_loss: 30712.2246 - val_mae: 28.3516\n",
            "Epoch 166/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 200.2908 - mae: 10.3271 - val_loss: 30677.1973 - val_mae: 28.0113\n",
            "Epoch 167/1000\n",
            "107/107 [==============================] - 6s 57ms/step - loss: 205.2487 - mae: 10.2881 - val_loss: 30213.4199 - val_mae: 28.1043\n",
            "Epoch 168/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 193.8924 - mae: 10.1723 - val_loss: 37962.8594 - val_mae: 31.0735\n",
            "Epoch 169/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 187.8755 - mae: 9.9658 - val_loss: 35496.5039 - val_mae: 29.8999\n",
            "Epoch 170/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 203.0938 - mae: 10.0262 - val_loss: 27396.3926 - val_mae: 26.7424\n",
            "Epoch 171/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 211.9972 - mae: 10.3613 - val_loss: 24590.9160 - val_mae: 26.0218\n",
            "Epoch 172/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 208.9600 - mae: 10.1164 - val_loss: 20855.2754 - val_mae: 24.2732\n",
            "Epoch 173/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 196.7906 - mae: 10.0593 - val_loss: 37630.5781 - val_mae: 30.7329\n",
            "Epoch 174/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 262.1078 - mae: 10.4399 - val_loss: 18169.7207 - val_mae: 22.8975\n",
            "Epoch 175/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 231.6993 - mae: 10.0884 - val_loss: 24423.6953 - val_mae: 26.0213\n",
            "Epoch 176/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 204.4925 - mae: 10.0687 - val_loss: 21894.5898 - val_mae: 24.6747\n",
            "Epoch 177/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 188.2099 - mae: 9.7661 - val_loss: 22289.6777 - val_mae: 24.8690\n",
            "Epoch 178/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 210.2086 - mae: 10.1587 - val_loss: 36590.1250 - val_mae: 30.3498\n",
            "Epoch 179/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 211.2956 - mae: 10.1960 - val_loss: 20315.5840 - val_mae: 23.7371\n",
            "Epoch 180/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 229.3186 - mae: 10.3086 - val_loss: 21767.0312 - val_mae: 24.7206\n",
            "Epoch 181/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 213.4647 - mae: 10.0814 - val_loss: 24551.2773 - val_mae: 26.0862\n",
            "Epoch 182/1000\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 196.5002 - mae: 9.9955 - val_loss: 20196.5059 - val_mae: 23.6822\n",
            "Epoch 183/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 203.1969 - mae: 9.9756 - val_loss: 40733.6094 - val_mae: 31.5910\n",
            "Epoch 184/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 213.1386 - mae: 10.0752 - val_loss: 22134.5117 - val_mae: 25.0616\n",
            "Epoch 185/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 227.3096 - mae: 10.1409 - val_loss: 22339.8594 - val_mae: 24.9804\n",
            "Epoch 186/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 234.3558 - mae: 10.1904 - val_loss: 34090.0273 - val_mae: 29.2496\n",
            "Epoch 187/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 196.7714 - mae: 9.7527 - val_loss: 23045.6484 - val_mae: 24.8862\n",
            "Epoch 188/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 224.5354 - mae: 10.2053 - val_loss: 29448.2715 - val_mae: 28.1006\n",
            "Epoch 189/1000\n",
            "107/107 [==============================] - 6s 55ms/step - loss: 202.0989 - mae: 10.0416 - val_loss: 28465.6191 - val_mae: 27.8180\n",
            "Epoch 190/1000\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 193.4060 - mae: 9.6361 - val_loss: 22755.3867 - val_mae: 24.8626\n",
            "Epoch 191/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 184.2650 - mae: 9.6576 - val_loss: 30732.5449 - val_mae: 27.6300\n",
            "Epoch 192/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 186.4853 - mae: 9.6761 - val_loss: 25795.0859 - val_mae: 26.2904\n",
            "Epoch 193/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 210.4223 - mae: 10.1171 - val_loss: 31845.7520 - val_mae: 28.4822\n",
            "Epoch 194/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 216.1957 - mae: 9.9154 - val_loss: 41396.5859 - val_mae: 32.5777\n",
            "Epoch 195/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 199.0905 - mae: 9.8804 - val_loss: 25608.4277 - val_mae: 26.1783\n",
            "Epoch 196/1000\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 188.5174 - mae: 9.7019 - val_loss: 23813.3223 - val_mae: 25.3588\n",
            "Epoch 197/1000\n",
            "107/107 [==============================] - 5s 50ms/step - loss: 204.0332 - mae: 9.6902 - val_loss: 29659.9102 - val_mae: 27.2666\n",
            "Epoch 198/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 201.5232 - mae: 9.4860 - val_loss: 29688.3223 - val_mae: 27.1653\n",
            "Epoch 199/1000\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 232.6173 - mae: 10.2207 - val_loss: 74.2959 - val_mae: 5.2278\n",
            "Epoch 200/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 213.6108 - mae: 9.9154 - val_loss: 17221.6465 - val_mae: 21.6976\n",
            "Epoch 201/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 208.7562 - mae: 9.8943 - val_loss: 22130.4883 - val_mae: 24.9231\n",
            "Epoch 202/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 203.0648 - mae: 9.6157 - val_loss: 22661.9844 - val_mae: 24.3995\n",
            "Epoch 203/1000\n",
            "107/107 [==============================] - 7s 63ms/step - loss: 212.0685 - mae: 9.7178 - val_loss: 22136.9609 - val_mae: 23.8820\n",
            "Epoch 204/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 231.7690 - mae: 10.0000 - val_loss: 21162.0605 - val_mae: 23.4967\n",
            "Epoch 205/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 205.7649 - mae: 9.7234 - val_loss: 23355.2422 - val_mae: 24.5332\n",
            "Epoch 206/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 224.0382 - mae: 9.9403 - val_loss: 16244.1719 - val_mae: 21.2940\n",
            "Epoch 207/1000\n",
            "107/107 [==============================] - 6s 58ms/step - loss: 192.3621 - mae: 9.5010 - val_loss: 27913.1855 - val_mae: 26.4512\n",
            "Epoch 208/1000\n",
            "107/107 [==============================] - 6s 55ms/step - loss: 218.0119 - mae: 9.9919 - val_loss: 37067.9375 - val_mae: 30.0961\n",
            "Epoch 209/1000\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 227.9747 - mae: 10.0325 - val_loss: 14545.8457 - val_mae: 20.6787\n",
            "Epoch 210/1000\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 218.8492 - mae: 9.8474 - val_loss: 12578.6396 - val_mae: 18.8628\n",
            "Epoch 211/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 182.2782 - mae: 9.4818 - val_loss: 51689.6797 - val_mae: 36.5374\n",
            "Epoch 212/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 329.2402 - mae: 10.6802 - val_loss: 47596.9727 - val_mae: 33.5010\n",
            "Epoch 213/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 210.6512 - mae: 9.7603 - val_loss: 63730.4766 - val_mae: 37.7262\n",
            "Epoch 214/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 210.5459 - mae: 9.7085 - val_loss: 62871.4023 - val_mae: 37.2752\n",
            "Epoch 215/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 210.3216 - mae: 10.0049 - val_loss: 43546.3125 - val_mae: 31.8578\n",
            "Epoch 216/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 185.0024 - mae: 9.6266 - val_loss: 52542.1445 - val_mae: 34.6484\n",
            "Epoch 217/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 168.6043 - mae: 9.4111 - val_loss: 50869.9609 - val_mae: 34.3065\n",
            "Epoch 218/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 200.0302 - mae: 9.8232 - val_loss: 48812.2227 - val_mae: 33.6156\n",
            "Epoch 219/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 244.9088 - mae: 9.9323 - val_loss: 36309.0664 - val_mae: 30.0024\n",
            "Epoch 220/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 206.2537 - mae: 9.8338 - val_loss: 38580.0742 - val_mae: 30.6884\n",
            "Epoch 221/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 192.3560 - mae: 9.5598 - val_loss: 40121.0625 - val_mae: 30.3816\n",
            "Epoch 222/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 188.1896 - mae: 9.6980 - val_loss: 58242.7695 - val_mae: 36.5112\n",
            "Epoch 223/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 189.4785 - mae: 9.6225 - val_loss: 36056.0508 - val_mae: 29.4723\n",
            "Epoch 224/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 188.7389 - mae: 9.6050 - val_loss: 45551.5039 - val_mae: 32.9410\n",
            "Epoch 225/1000\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 285.4213 - mae: 10.4403 - val_loss: 43613.1289 - val_mae: 32.4644\n",
            "Epoch 226/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 212.5100 - mae: 9.7263 - val_loss: 38692.9883 - val_mae: 30.6279\n",
            "Epoch 227/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 206.0806 - mae: 9.8176 - val_loss: 36393.8516 - val_mae: 29.6987\n",
            "Epoch 228/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 212.3484 - mae: 9.7762 - val_loss: 26674.1406 - val_mae: 26.4950\n",
            "Epoch 229/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 168.1077 - mae: 9.4559 - val_loss: 17619.1367 - val_mae: 21.5524\n",
            "Epoch 230/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 183.8884 - mae: 9.4227 - val_loss: 20485.6484 - val_mae: 22.5169\n",
            "Epoch 231/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 191.8801 - mae: 9.5244 - val_loss: 40376.4297 - val_mae: 30.6326\n",
            "Epoch 232/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 171.3888 - mae: 9.3831 - val_loss: 26363.9160 - val_mae: 26.1769\n",
            "Epoch 233/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 197.6571 - mae: 9.4958 - val_loss: 34954.3008 - val_mae: 28.8763\n",
            "Epoch 234/1000\n",
            "107/107 [==============================] - 7s 61ms/step - loss: 172.0221 - mae: 9.3450 - val_loss: 32793.7812 - val_mae: 27.8053\n",
            "Epoch 235/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 164.7072 - mae: 9.1588 - val_loss: 31104.3066 - val_mae: 27.1711\n",
            "Epoch 236/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 177.4942 - mae: 9.4049 - val_loss: 66470.1328 - val_mae: 38.5999\n",
            "Epoch 237/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 189.1910 - mae: 9.6921 - val_loss: 76134.8359 - val_mae: 40.4556\n",
            "Epoch 238/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 190.9034 - mae: 9.6415 - val_loss: 84054.8125 - val_mae: 42.6125\n",
            "Epoch 239/1000\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 241.0591 - mae: 10.3633 - val_loss: 35685.5078 - val_mae: 29.6421\n",
            "Epoch 240/1000\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 184.6808 - mae: 9.7736 - val_loss: 77990.0938 - val_mae: 41.8054\n",
            "Epoch 241/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 204.4170 - mae: 9.6254 - val_loss: 47734.8086 - val_mae: 33.5173\n",
            "Epoch 242/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 189.5763 - mae: 9.6389 - val_loss: 38697.2734 - val_mae: 30.1704\n",
            "Epoch 243/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 218.0575 - mae: 9.6629 - val_loss: 32649.9980 - val_mae: 28.1326\n",
            "Epoch 244/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 226.3862 - mae: 9.8269 - val_loss: 22960.8438 - val_mae: 23.9306\n",
            "Epoch 245/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 198.5930 - mae: 9.7619 - val_loss: 22435.7598 - val_mae: 24.4616\n",
            "Epoch 246/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 224.8534 - mae: 10.1090 - val_loss: 19014.3750 - val_mae: 22.8625\n",
            "Epoch 247/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 214.2097 - mae: 9.8570 - val_loss: 16782.1719 - val_mae: 21.9526\n",
            "Epoch 248/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 198.3454 - mae: 9.8774 - val_loss: 22349.7129 - val_mae: 24.5663\n",
            "Epoch 249/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 208.7673 - mae: 9.6759 - val_loss: 13063.0117 - val_mae: 19.7090\n",
            "Epoch 250/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 186.0879 - mae: 9.4018 - val_loss: 12798.9150 - val_mae: 18.9331\n",
            "Epoch 251/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 251.8978 - mae: 9.7912 - val_loss: 7313.0244 - val_mae: 15.3249\n",
            "Epoch 252/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 227.4784 - mae: 9.6716 - val_loss: 9410.5332 - val_mae: 16.7676\n",
            "Epoch 253/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 186.2129 - mae: 9.6336 - val_loss: 37485.4609 - val_mae: 31.6460\n",
            "Epoch 254/1000\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 203.0709 - mae: 9.7780 - val_loss: 97292.6797 - val_mae: 45.6558\n",
            "Epoch 255/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 231.1831 - mae: 10.0284 - val_loss: 31045.3516 - val_mae: 28.6509\n",
            "Epoch 256/1000\n",
            "107/107 [==============================] - 7s 63ms/step - loss: 233.4961 - mae: 10.0777 - val_loss: 27652.9512 - val_mae: 27.3095\n",
            "Epoch 257/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 216.9411 - mae: 10.2206 - val_loss: 32027.9258 - val_mae: 29.2038\n",
            "Epoch 258/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 195.2790 - mae: 9.9275 - val_loss: 41964.1562 - val_mae: 32.3866\n",
            "Epoch 259/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 210.8903 - mae: 9.9551 - val_loss: 29067.6582 - val_mae: 27.7551\n",
            "Epoch 260/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 199.4944 - mae: 10.0572 - val_loss: 31975.8242 - val_mae: 28.8384\n",
            "Epoch 261/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 201.6106 - mae: 9.8846 - val_loss: 28249.1055 - val_mae: 27.5749\n",
            "Epoch 262/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 187.2747 - mae: 9.7531 - val_loss: 24140.8086 - val_mae: 25.6839\n",
            "Epoch 263/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 203.4158 - mae: 9.5781 - val_loss: 34703.1953 - val_mae: 29.4090\n",
            "Epoch 264/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 198.2043 - mae: 9.6507 - val_loss: 31785.5703 - val_mae: 28.1895\n",
            "Epoch 265/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 187.4128 - mae: 9.5405 - val_loss: 27819.6602 - val_mae: 27.0034\n",
            "Epoch 266/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 196.0868 - mae: 9.5290 - val_loss: 35300.7578 - val_mae: 30.0618\n",
            "Epoch 267/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 187.2563 - mae: 9.5699 - val_loss: 29767.4199 - val_mae: 27.9889\n",
            "Epoch 268/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 203.6488 - mae: 9.3857 - val_loss: 22958.7734 - val_mae: 24.5476\n",
            "Epoch 269/1000\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 176.4065 - mae: 9.4686 - val_loss: 22693.0156 - val_mae: 24.6250\n",
            "Epoch 270/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 195.6157 - mae: 9.5513 - val_loss: 17593.0410 - val_mae: 22.0528\n",
            "Epoch 271/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 208.2304 - mae: 9.5765 - val_loss: 26189.3965 - val_mae: 26.3494\n",
            "Epoch 272/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 177.4571 - mae: 9.3879 - val_loss: 46923.4844 - val_mae: 33.9007\n",
            "Epoch 273/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 227.9707 - mae: 9.7395 - val_loss: 27908.4805 - val_mae: 27.3111\n",
            "Epoch 274/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 184.5084 - mae: 9.5733 - val_loss: 52797.2344 - val_mae: 35.2770\n",
            "Epoch 275/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 206.2060 - mae: 9.6265 - val_loss: 37202.0039 - val_mae: 30.2734\n",
            "Epoch 276/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 198.8797 - mae: 9.5987 - val_loss: 45821.9727 - val_mae: 33.5218\n",
            "Epoch 277/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 235.4681 - mae: 9.8042 - val_loss: 43916.4531 - val_mae: 32.4299\n",
            "Epoch 278/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 209.5124 - mae: 9.4181 - val_loss: 24007.9609 - val_mae: 25.3503\n",
            "Epoch 279/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 185.0720 - mae: 9.2021 - val_loss: 15216.7598 - val_mae: 20.5805\n",
            "Epoch 280/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 182.8692 - mae: 9.3465 - val_loss: 12901.9326 - val_mae: 19.4624\n",
            "Epoch 281/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 190.3298 - mae: 9.4162 - val_loss: 10253.3711 - val_mae: 18.0555\n",
            "Epoch 282/1000\n",
            "107/107 [==============================] - 3s 32ms/step - loss: 194.5359 - mae: 9.4508 - val_loss: 10997.2080 - val_mae: 18.3841\n",
            "Epoch 283/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 174.1780 - mae: 9.2905 - val_loss: 13685.9004 - val_mae: 20.4683\n",
            "Epoch 284/1000\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 197.8460 - mae: 9.5293 - val_loss: 14912.3916 - val_mae: 20.9499\n",
            "Epoch 285/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 199.7437 - mae: 9.3393 - val_loss: 18800.1934 - val_mae: 23.0082\n",
            "Epoch 286/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 179.3606 - mae: 9.3062 - val_loss: 15240.4951 - val_mae: 21.0590\n",
            "Epoch 287/1000\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 161.7954 - mae: 8.9236 - val_loss: 13434.2793 - val_mae: 19.7806\n",
            "Epoch 288/1000\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 160.2729 - mae: 8.9781 - val_loss: 5566.3857 - val_mae: 14.6942\n",
            "Epoch 289/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 180.3489 - mae: 9.1043 - val_loss: 20371.0332 - val_mae: 23.3350\n",
            "Epoch 290/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 165.6299 - mae: 8.9118 - val_loss: 18869.9395 - val_mae: 22.0583\n",
            "Epoch 291/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 187.7557 - mae: 9.4204 - val_loss: 12574.1250 - val_mae: 19.2100\n",
            "Epoch 292/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 146.1835 - mae: 8.7591 - val_loss: 19456.7031 - val_mae: 22.7013\n",
            "Epoch 293/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 161.6061 - mae: 9.1651 - val_loss: 23716.8281 - val_mae: 24.6492\n",
            "Epoch 294/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 169.1810 - mae: 9.0686 - val_loss: 12388.0938 - val_mae: 19.3934\n",
            "Epoch 295/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 173.2814 - mae: 9.2042 - val_loss: 16985.1797 - val_mae: 21.4735\n",
            "Epoch 296/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 182.7216 - mae: 9.0669 - val_loss: 18953.2051 - val_mae: 22.3823\n",
            "Epoch 297/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 156.0618 - mae: 8.7209 - val_loss: 19982.4648 - val_mae: 22.6094\n",
            "Epoch 298/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 187.0657 - mae: 9.5826 - val_loss: 12616.8242 - val_mae: 19.7528\n",
            "Epoch 299/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 193.4632 - mae: 9.3375 - val_loss: 14429.9170 - val_mae: 20.5857\n",
            "Epoch 300/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 173.3599 - mae: 9.2660 - val_loss: 16307.4551 - val_mae: 21.6581\n",
            "Epoch 301/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 171.1811 - mae: 9.0739 - val_loss: 20478.2461 - val_mae: 23.1031\n",
            "Epoch 302/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 171.9038 - mae: 9.1761 - val_loss: 21453.2578 - val_mae: 23.8939\n",
            "Epoch 303/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 202.0286 - mae: 9.4515 - val_loss: 24566.8359 - val_mae: 25.3025\n",
            "Epoch 304/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 225.3579 - mae: 9.5506 - val_loss: 931.1998 - val_mae: 9.4693\n",
            "Epoch 305/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 217.0326 - mae: 9.7113 - val_loss: 10406.6143 - val_mae: 17.4900\n",
            "Epoch 306/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 206.0969 - mae: 9.5297 - val_loss: 17732.2559 - val_mae: 22.0473\n",
            "Epoch 307/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 225.5449 - mae: 9.6294 - val_loss: 37592.0586 - val_mae: 29.9891\n",
            "Epoch 308/1000\n",
            "107/107 [==============================] - 6s 59ms/step - loss: 176.4486 - mae: 9.3589 - val_loss: 32221.5352 - val_mae: 28.5342\n",
            "Epoch 309/1000\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 181.8382 - mae: 9.3481 - val_loss: 44802.5156 - val_mae: 32.7729\n",
            "Epoch 310/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 171.3614 - mae: 9.1597 - val_loss: 23202.4473 - val_mae: 24.8372\n",
            "Epoch 311/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 186.4474 - mae: 9.3575 - val_loss: 25682.1855 - val_mae: 26.3184\n",
            "Epoch 312/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 190.8179 - mae: 9.1983 - val_loss: 38961.2578 - val_mae: 30.6302\n",
            "Epoch 313/1000\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 156.3015 - mae: 9.2543 - val_loss: 19481.4453 - val_mae: 23.2233\n",
            "Epoch 314/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 196.8361 - mae: 9.3312 - val_loss: 27204.8301 - val_mae: 26.1915\n",
            "Epoch 315/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 165.3107 - mae: 8.9451 - val_loss: 44495.7461 - val_mae: 32.9742\n",
            "Epoch 316/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 194.7265 - mae: 9.4159 - val_loss: 29693.6133 - val_mae: 27.3901\n",
            "Epoch 317/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 182.3446 - mae: 9.0746 - val_loss: 24982.7949 - val_mae: 25.5825\n",
            "Epoch 318/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 219.7114 - mae: 9.5710 - val_loss: 27013.5996 - val_mae: 26.7383\n",
            "Epoch 319/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 181.9557 - mae: 9.3066 - val_loss: 23830.7559 - val_mae: 25.0790\n",
            "Epoch 320/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 164.5097 - mae: 8.9508 - val_loss: 21381.4238 - val_mae: 23.8359\n",
            "Epoch 321/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 179.2564 - mae: 9.2641 - val_loss: 14858.0723 - val_mae: 21.0353\n",
            "Epoch 322/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 172.1588 - mae: 9.2115 - val_loss: 17068.6543 - val_mae: 22.6797\n",
            "Epoch 323/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 191.0508 - mae: 9.5541 - val_loss: 23648.3984 - val_mae: 25.4447\n",
            "Epoch 324/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 182.7690 - mae: 9.4400 - val_loss: 24986.1523 - val_mae: 25.8652\n",
            "Epoch 325/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 173.4140 - mae: 9.2488 - val_loss: 18159.6289 - val_mae: 22.3292\n",
            "Epoch 326/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 167.6700 - mae: 9.2159 - val_loss: 21691.1328 - val_mae: 24.0808\n",
            "Epoch 327/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 157.1071 - mae: 8.7655 - val_loss: 23922.5898 - val_mae: 24.8445\n",
            "Epoch 328/1000\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 165.0330 - mae: 9.2122 - val_loss: 25573.4531 - val_mae: 26.0369\n",
            "Epoch 329/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 163.6827 - mae: 8.8296 - val_loss: 26067.2227 - val_mae: 25.8051\n",
            "Epoch 330/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 152.4603 - mae: 8.9971 - val_loss: 24655.4688 - val_mae: 25.6093\n",
            "Epoch 331/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 172.1414 - mae: 8.9914 - val_loss: 24081.4805 - val_mae: 24.8382\n",
            "Epoch 332/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 174.5298 - mae: 9.1293 - val_loss: 25730.9844 - val_mae: 25.5506\n",
            "Epoch 333/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 206.8633 - mae: 9.2862 - val_loss: 22590.8164 - val_mae: 24.4595\n",
            "Epoch 334/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 164.7082 - mae: 8.9579 - val_loss: 22859.7129 - val_mae: 25.2925\n",
            "Epoch 335/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 168.1231 - mae: 9.2495 - val_loss: 21844.4766 - val_mae: 24.3096\n",
            "Epoch 336/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 175.0078 - mae: 9.2079 - val_loss: 22410.1328 - val_mae: 24.6686\n",
            "Epoch 337/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 180.7144 - mae: 9.3068 - val_loss: 19627.7363 - val_mae: 23.3226\n",
            "Epoch 338/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 162.3575 - mae: 8.8671 - val_loss: 31399.1289 - val_mae: 28.4307\n",
            "Epoch 339/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 147.8906 - mae: 9.0148 - val_loss: 22622.3535 - val_mae: 25.2157\n",
            "Epoch 340/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 177.3893 - mae: 9.1014 - val_loss: 23917.3027 - val_mae: 25.3527\n",
            "Epoch 341/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 185.6756 - mae: 9.0884 - val_loss: 24700.3887 - val_mae: 25.6384\n",
            "Epoch 342/1000\n",
            "107/107 [==============================] - 6s 56ms/step - loss: 196.9242 - mae: 9.2753 - val_loss: 31620.0391 - val_mae: 28.1488\n",
            "Epoch 343/1000\n",
            "107/107 [==============================] - 8s 77ms/step - loss: 165.1349 - mae: 9.2829 - val_loss: 18850.2168 - val_mae: 23.1006\n",
            "Epoch 344/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 174.0929 - mae: 9.1194 - val_loss: 19347.7305 - val_mae: 23.1737\n",
            "Epoch 345/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 165.9274 - mae: 8.9566 - val_loss: 19364.0020 - val_mae: 22.7909\n",
            "Epoch 346/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 154.0883 - mae: 9.0006 - val_loss: 18970.2988 - val_mae: 23.1848\n",
            "Epoch 347/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 152.5592 - mae: 8.7591 - val_loss: 34960.6641 - val_mae: 29.5421\n",
            "Epoch 348/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 166.8897 - mae: 9.0252 - val_loss: 43276.0859 - val_mae: 32.4922\n",
            "Epoch 349/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 167.0897 - mae: 8.5899 - val_loss: 33482.2109 - val_mae: 29.0371\n",
            "Epoch 350/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 158.9656 - mae: 8.8256 - val_loss: 41145.1836 - val_mae: 31.6641\n",
            "Epoch 351/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 170.2992 - mae: 8.8974 - val_loss: 37315.0273 - val_mae: 30.5877\n",
            "Epoch 352/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 182.0166 - mae: 9.0115 - val_loss: 13433.7773 - val_mae: 20.0310\n",
            "Epoch 353/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 243.6271 - mae: 9.9951 - val_loss: 49470.0625 - val_mae: 35.1155\n",
            "Epoch 354/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 194.9128 - mae: 9.6657 - val_loss: 51640.1875 - val_mae: 35.1277\n",
            "Epoch 355/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 208.2352 - mae: 9.3018 - val_loss: 48417.1680 - val_mae: 33.7308\n",
            "Epoch 356/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 196.0173 - mae: 9.1816 - val_loss: 38502.9883 - val_mae: 29.9480\n",
            "Epoch 357/1000\n",
            "107/107 [==============================] - 5s 51ms/step - loss: 194.3627 - mae: 9.3112 - val_loss: 28737.2070 - val_mae: 26.7315\n",
            "Epoch 358/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 176.1053 - mae: 9.1012 - val_loss: 34205.8398 - val_mae: 28.7067\n",
            "Epoch 359/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 160.9182 - mae: 8.8726 - val_loss: 21603.1621 - val_mae: 23.6508\n",
            "Epoch 360/1000\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 162.3724 - mae: 9.0538 - val_loss: 24779.5605 - val_mae: 25.0924\n",
            "Epoch 361/1000\n",
            "107/107 [==============================] - 6s 54ms/step - loss: 156.1835 - mae: 9.0223 - val_loss: 45402.1602 - val_mae: 32.5236\n",
            "Epoch 362/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 175.2098 - mae: 8.9795 - val_loss: 37361.8008 - val_mae: 29.7219\n",
            "Epoch 363/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 190.0833 - mae: 8.9902 - val_loss: 47193.7188 - val_mae: 32.4470\n",
            "Epoch 364/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 194.0097 - mae: 9.2007 - val_loss: 42945.8320 - val_mae: 31.6604\n",
            "Epoch 365/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 172.8583 - mae: 9.3175 - val_loss: 35033.0977 - val_mae: 29.2019\n",
            "Epoch 366/1000\n",
            "107/107 [==============================] - 3s 33ms/step - loss: 153.5195 - mae: 8.5458 - val_loss: 24461.2656 - val_mae: 24.8298\n",
            "Epoch 367/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 166.7396 - mae: 8.9301 - val_loss: 26144.3809 - val_mae: 25.4483\n",
            "Epoch 368/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 164.9700 - mae: 8.6515 - val_loss: 30083.5117 - val_mae: 26.8555\n",
            "Epoch 369/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 158.6622 - mae: 8.7366 - val_loss: 30044.7500 - val_mae: 26.9003\n",
            "Epoch 370/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 161.5996 - mae: 8.6596 - val_loss: 29240.9863 - val_mae: 26.8166\n",
            "Epoch 371/1000\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 165.6984 - mae: 8.5840 - val_loss: 27301.8594 - val_mae: 25.7431\n",
            "Epoch 372/1000\n",
            "107/107 [==============================] - 5s 51ms/step - loss: 147.6546 - mae: 8.6634 - val_loss: 18089.2988 - val_mae: 22.1816\n",
            "Epoch 373/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 154.3094 - mae: 8.8488 - val_loss: 27696.6406 - val_mae: 26.2521\n",
            "Epoch 374/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 152.6355 - mae: 8.7340 - val_loss: 26645.2520 - val_mae: 25.7380\n",
            "Epoch 375/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 161.6418 - mae: 8.7599 - val_loss: 26350.2598 - val_mae: 25.3155\n",
            "Epoch 376/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 209.4206 - mae: 9.0825 - val_loss: 19279.6543 - val_mae: 22.2545\n",
            "Epoch 377/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 162.4389 - mae: 8.7486 - val_loss: 31292.9023 - val_mae: 27.2458\n",
            "Epoch 378/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 181.6084 - mae: 8.9919 - val_loss: 28121.3496 - val_mae: 26.4709\n",
            "Epoch 379/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 179.1180 - mae: 8.6806 - val_loss: 20993.3359 - val_mae: 23.5718\n",
            "Epoch 380/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 211.5570 - mae: 9.3218 - val_loss: 566.7402 - val_mae: 7.3892\n",
            "Epoch 381/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 175.6656 - mae: 9.1887 - val_loss: 21313.2324 - val_mae: 24.1271\n",
            "Epoch 382/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 203.0870 - mae: 8.9740 - val_loss: 27691.8359 - val_mae: 26.1495\n",
            "Epoch 383/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 169.1509 - mae: 8.7406 - val_loss: 21040.3301 - val_mae: 23.2980\n",
            "Epoch 384/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 168.5701 - mae: 8.8039 - val_loss: 25827.2344 - val_mae: 25.0344\n",
            "Epoch 385/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 152.1447 - mae: 8.5594 - val_loss: 471.3356 - val_mae: 6.2936\n",
            "Epoch 386/1000\n",
            "107/107 [==============================] - 5s 51ms/step - loss: 205.3860 - mae: 8.9745 - val_loss: 498.1341 - val_mae: 7.0236\n",
            "Epoch 387/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 174.9506 - mae: 9.0431 - val_loss: 18063.3223 - val_mae: 22.7737\n",
            "Epoch 388/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 199.8585 - mae: 9.2654 - val_loss: 22806.2383 - val_mae: 23.6822\n",
            "Epoch 389/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 154.1449 - mae: 8.5599 - val_loss: 17089.3047 - val_mae: 21.0785\n",
            "Epoch 390/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 181.8920 - mae: 9.3331 - val_loss: 16914.7500 - val_mae: 21.0499\n",
            "Epoch 391/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 166.3020 - mae: 8.7201 - val_loss: 19165.9141 - val_mae: 21.5536\n",
            "Epoch 392/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 156.5293 - mae: 8.6001 - val_loss: 24489.5293 - val_mae: 24.3016\n",
            "Epoch 393/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 201.6497 - mae: 9.1686 - val_loss: 17349.3477 - val_mae: 20.9324\n",
            "Epoch 394/1000\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 187.7220 - mae: 8.8080 - val_loss: 22611.3574 - val_mae: 23.4343\n",
            "Epoch 395/1000\n",
            "107/107 [==============================] - 7s 65ms/step - loss: 165.0640 - mae: 8.6009 - val_loss: 17538.5449 - val_mae: 21.3291\n",
            "Epoch 396/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 169.0581 - mae: 8.8142 - val_loss: 20112.6992 - val_mae: 22.3756\n",
            "Epoch 397/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 153.7566 - mae: 8.7250 - val_loss: 11719.7705 - val_mae: 18.3681\n",
            "Epoch 398/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 190.6398 - mae: 8.9378 - val_loss: 13911.8281 - val_mae: 19.5775\n",
            "Epoch 399/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 166.8308 - mae: 8.6931 - val_loss: 12226.5547 - val_mae: 18.4699\n",
            "Epoch 400/1000\n",
            "107/107 [==============================] - 5s 50ms/step - loss: 157.4259 - mae: 8.4531 - val_loss: 14898.2148 - val_mae: 19.9469\n",
            "Epoch 401/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 173.0603 - mae: 8.7652 - val_loss: 17240.2324 - val_mae: 22.0151\n",
            "Epoch 402/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 178.4339 - mae: 8.6397 - val_loss: 22357.4688 - val_mae: 23.8614\n",
            "Epoch 403/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 151.8754 - mae: 8.5493 - val_loss: 10037.4521 - val_mae: 16.9211\n",
            "Epoch 404/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 189.7540 - mae: 8.9551 - val_loss: 29447.9785 - val_mae: 26.7825\n",
            "Epoch 405/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 187.6709 - mae: 8.9786 - val_loss: 15770.3828 - val_mae: 20.4641\n",
            "Epoch 406/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 151.1775 - mae: 8.5758 - val_loss: 15301.0850 - val_mae: 20.3575\n",
            "Epoch 407/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 161.7730 - mae: 8.6034 - val_loss: 10587.9951 - val_mae: 16.9230\n",
            "Epoch 408/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 164.1476 - mae: 8.6571 - val_loss: 6224.6787 - val_mae: 14.0731\n",
            "Epoch 409/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 167.1512 - mae: 8.5351 - val_loss: 1231.7825 - val_mae: 8.8405\n",
            "Epoch 410/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 151.8097 - mae: 8.6232 - val_loss: 10244.3721 - val_mae: 17.7824\n",
            "Epoch 411/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 126.8149 - mae: 8.1750 - val_loss: 12265.8477 - val_mae: 18.4421\n",
            "Epoch 412/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 136.0683 - mae: 8.2792 - val_loss: 11803.5928 - val_mae: 17.8890\n",
            "Epoch 413/1000\n",
            "107/107 [==============================] - 6s 59ms/step - loss: 158.2910 - mae: 8.5273 - val_loss: 12408.5547 - val_mae: 18.4721\n",
            "Epoch 414/1000\n",
            "107/107 [==============================] - 8s 76ms/step - loss: 141.9540 - mae: 8.2234 - val_loss: 13032.4492 - val_mae: 18.6013\n",
            "Epoch 415/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 137.2910 - mae: 8.3793 - val_loss: 10147.3809 - val_mae: 17.2668\n",
            "Epoch 416/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 182.6749 - mae: 8.7098 - val_loss: 12558.2197 - val_mae: 18.5624\n",
            "Epoch 417/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 145.9182 - mae: 8.4168 - val_loss: 12903.2266 - val_mae: 18.7845\n",
            "Epoch 418/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 181.8037 - mae: 8.5523 - val_loss: 10465.5498 - val_mae: 17.1812\n",
            "Epoch 419/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 135.3615 - mae: 8.1370 - val_loss: 12201.6553 - val_mae: 18.2758\n",
            "Epoch 420/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 139.8593 - mae: 8.3210 - val_loss: 14506.6514 - val_mae: 19.8767\n",
            "Epoch 421/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 131.7176 - mae: 8.2404 - val_loss: 18499.3809 - val_mae: 21.6570\n",
            "Epoch 422/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 214.9526 - mae: 8.7265 - val_loss: 19671.5059 - val_mae: 22.9541\n",
            "Epoch 423/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 163.1846 - mae: 8.5617 - val_loss: 12353.5752 - val_mae: 19.0153\n",
            "Epoch 424/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 163.6189 - mae: 8.5406 - val_loss: 15797.3750 - val_mae: 20.5408\n",
            "Epoch 425/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 151.9208 - mae: 8.4174 - val_loss: 12737.2109 - val_mae: 18.8878\n",
            "Epoch 426/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 163.0837 - mae: 8.5759 - val_loss: 9532.3643 - val_mae: 16.6406\n",
            "Epoch 427/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 151.9428 - mae: 8.4894 - val_loss: 9755.8916 - val_mae: 16.6660\n",
            "Epoch 428/1000\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 150.2250 - mae: 8.5050 - val_loss: 10805.1709 - val_mae: 17.4925\n",
            "Epoch 429/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 166.9315 - mae: 8.4001 - val_loss: 8557.4775 - val_mae: 16.4628\n",
            "Epoch 430/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 157.2823 - mae: 8.3498 - val_loss: 20644.3691 - val_mae: 22.9816\n",
            "Epoch 431/1000\n",
            "107/107 [==============================] - 4s 33ms/step - loss: 153.4248 - mae: 8.3816 - val_loss: 25793.7402 - val_mae: 24.9674\n",
            "Epoch 432/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 172.8039 - mae: 8.6374 - val_loss: 22704.3516 - val_mae: 23.5141\n",
            "Epoch 433/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 157.6475 - mae: 8.5833 - val_loss: 23858.7734 - val_mae: 24.3755\n",
            "Epoch 434/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 183.9651 - mae: 8.7314 - val_loss: 22871.9668 - val_mae: 24.0569\n",
            "Epoch 435/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 179.2878 - mae: 8.4754 - val_loss: 17638.2598 - val_mae: 21.4884\n",
            "Epoch 436/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 175.4955 - mae: 8.6618 - val_loss: 18885.8398 - val_mae: 22.0500\n",
            "Epoch 437/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 140.4344 - mae: 8.5457 - val_loss: 23417.1055 - val_mae: 24.3613\n",
            "Epoch 438/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 157.2646 - mae: 8.5021 - val_loss: 20762.8965 - val_mae: 23.4219\n",
            "Epoch 439/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 188.4768 - mae: 8.7390 - val_loss: 20649.5273 - val_mae: 24.3295\n",
            "Epoch 440/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 267.4751 - mae: 9.5470 - val_loss: 9070.0361 - val_mae: 16.4609\n",
            "Epoch 441/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 241.1517 - mae: 9.6015 - val_loss: 23840.9082 - val_mae: 24.7824\n",
            "Epoch 442/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 243.2969 - mae: 9.8232 - val_loss: 34107.7773 - val_mae: 29.1733\n",
            "Epoch 443/1000\n",
            "107/107 [==============================] - 7s 62ms/step - loss: 195.1875 - mae: 9.1964 - val_loss: 19980.7676 - val_mae: 23.1184\n",
            "Epoch 444/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 163.9550 - mae: 8.8741 - val_loss: 18017.0977 - val_mae: 21.9503\n",
            "Epoch 445/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 186.7030 - mae: 8.9268 - val_loss: 10916.8574 - val_mae: 17.9241\n",
            "Epoch 446/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 183.9617 - mae: 8.7942 - val_loss: 9368.6973 - val_mae: 16.8151\n",
            "Epoch 447/1000\n",
            "107/107 [==============================] - 7s 66ms/step - loss: 161.1552 - mae: 8.6397 - val_loss: 13303.2607 - val_mae: 19.5230\n",
            "Epoch 448/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 178.6053 - mae: 8.8771 - val_loss: 13582.7295 - val_mae: 19.7020\n",
            "Epoch 449/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 146.0870 - mae: 8.6035 - val_loss: 10104.2441 - val_mae: 17.4532\n",
            "Epoch 450/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 143.3054 - mae: 8.6511 - val_loss: 10531.0273 - val_mae: 17.7447\n",
            "Epoch 451/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 171.1329 - mae: 8.7710 - val_loss: 17222.7266 - val_mae: 21.6537\n",
            "Epoch 452/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 214.5344 - mae: 9.0027 - val_loss: 18258.0547 - val_mae: 21.9733\n",
            "Epoch 453/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 191.5525 - mae: 8.9764 - val_loss: 11105.8379 - val_mae: 18.2052\n",
            "Epoch 454/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 192.2982 - mae: 9.0824 - val_loss: 7015.4683 - val_mae: 15.2046\n",
            "Epoch 455/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 157.9097 - mae: 8.8770 - val_loss: 12388.4980 - val_mae: 19.4224\n",
            "Epoch 456/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 156.0083 - mae: 8.8800 - val_loss: 9776.2383 - val_mae: 17.1961\n",
            "Epoch 457/1000\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 161.7995 - mae: 8.7794 - val_loss: 11372.0879 - val_mae: 18.2657\n",
            "Epoch 458/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 155.2022 - mae: 8.7059 - val_loss: 11337.0420 - val_mae: 18.2680\n",
            "Epoch 459/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 188.8239 - mae: 8.5325 - val_loss: 6863.0601 - val_mae: 15.1673\n",
            "Epoch 460/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 153.3324 - mae: 8.5741 - val_loss: 6993.0840 - val_mae: 15.3325\n",
            "Epoch 461/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 169.2984 - mae: 8.7682 - val_loss: 11055.0420 - val_mae: 17.8801\n",
            "Epoch 462/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 154.6952 - mae: 8.6025 - val_loss: 8220.0898 - val_mae: 16.0654\n",
            "Epoch 463/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 158.9526 - mae: 8.6386 - val_loss: 9137.3838 - val_mae: 16.7183\n",
            "Epoch 464/1000\n",
            "107/107 [==============================] - 6s 57ms/step - loss: 180.2344 - mae: 8.7452 - val_loss: 4180.0244 - val_mae: 12.5173\n",
            "Epoch 465/1000\n",
            "107/107 [==============================] - 6s 53ms/step - loss: 155.0616 - mae: 8.7151 - val_loss: 7472.0571 - val_mae: 15.4831\n",
            "Epoch 466/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 160.5113 - mae: 8.5933 - val_loss: 17534.9238 - val_mae: 21.7944\n",
            "Epoch 467/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 155.5422 - mae: 8.4333 - val_loss: 17361.0547 - val_mae: 21.7868\n",
            "Epoch 468/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 165.7432 - mae: 8.9764 - val_loss: 14182.9551 - val_mae: 19.8296\n",
            "Epoch 469/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 151.9868 - mae: 8.4136 - val_loss: 4590.4438 - val_mae: 12.9304\n",
            "Epoch 470/1000\n",
            "107/107 [==============================] - 6s 53ms/step - loss: 172.5819 - mae: 8.7022 - val_loss: 3957.2085 - val_mae: 12.4295\n",
            "Epoch 471/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 146.8824 - mae: 8.3021 - val_loss: 18274.9434 - val_mae: 21.8498\n",
            "Epoch 472/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 150.7186 - mae: 8.4835 - val_loss: 12056.6465 - val_mae: 18.5609\n",
            "Epoch 473/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 176.0166 - mae: 8.5722 - val_loss: 10179.3740 - val_mae: 17.5988\n",
            "Epoch 474/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 189.4839 - mae: 8.9880 - val_loss: 8814.9570 - val_mae: 16.6364\n",
            "Epoch 475/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 149.9644 - mae: 8.5097 - val_loss: 7235.7671 - val_mae: 15.4119\n",
            "Epoch 476/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 163.7929 - mae: 8.7230 - val_loss: 7230.5986 - val_mae: 15.8277\n",
            "Epoch 477/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 153.2243 - mae: 8.6542 - val_loss: 6663.6870 - val_mae: 15.3095\n",
            "Epoch 478/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 163.2628 - mae: 8.9792 - val_loss: 6802.7803 - val_mae: 15.1340\n",
            "Epoch 479/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 140.9003 - mae: 8.5086 - val_loss: 7678.2539 - val_mae: 15.8761\n",
            "Epoch 480/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 133.7385 - mae: 8.3219 - val_loss: 11604.6846 - val_mae: 18.0286\n",
            "Epoch 481/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 142.4245 - mae: 8.5611 - val_loss: 9249.0957 - val_mae: 16.3313\n",
            "Epoch 482/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 155.3820 - mae: 8.3748 - val_loss: 7940.5122 - val_mae: 15.6660\n",
            "Epoch 483/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 158.3318 - mae: 8.5048 - val_loss: 10230.3359 - val_mae: 17.0186\n",
            "Epoch 484/1000\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 143.9956 - mae: 8.4346 - val_loss: 9692.3320 - val_mae: 17.1410\n",
            "Epoch 485/1000\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 164.5014 - mae: 8.3769 - val_loss: 6636.6294 - val_mae: 14.7917\n",
            "Epoch 486/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 180.4276 - mae: 8.9153 - val_loss: 9754.5820 - val_mae: 17.0936\n",
            "Epoch 487/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 197.2946 - mae: 8.8594 - val_loss: 6023.1904 - val_mae: 14.1447\n",
            "Epoch 488/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 166.9722 - mae: 8.5726 - val_loss: 9271.6016 - val_mae: 16.7796\n",
            "Epoch 489/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 152.4704 - mae: 8.5108 - val_loss: 9364.8350 - val_mae: 16.7052\n",
            "Epoch 490/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 161.7232 - mae: 8.1582 - val_loss: 7156.7485 - val_mae: 15.0255\n",
            "Epoch 491/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 138.1908 - mae: 8.2878 - val_loss: 5755.3286 - val_mae: 13.8548\n",
            "Epoch 492/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 133.8640 - mae: 8.3951 - val_loss: 6186.3960 - val_mae: 14.3169\n",
            "Epoch 493/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 149.7704 - mae: 8.3642 - val_loss: 7352.5684 - val_mae: 15.2698\n",
            "Epoch 494/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 125.7025 - mae: 8.1391 - val_loss: 5294.8667 - val_mae: 13.3349\n",
            "Epoch 495/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 142.4492 - mae: 8.2666 - val_loss: 6399.0093 - val_mae: 14.3143\n",
            "Epoch 496/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 190.7527 - mae: 8.5656 - val_loss: 5221.1440 - val_mae: 13.1160\n",
            "Epoch 497/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 144.1981 - mae: 8.3379 - val_loss: 5346.9170 - val_mae: 13.2777\n",
            "Epoch 498/1000\n",
            "107/107 [==============================] - 9s 80ms/step - loss: 137.4181 - mae: 8.2260 - val_loss: 3919.0029 - val_mae: 12.0701\n",
            "Epoch 499/1000\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 134.7763 - mae: 8.2712 - val_loss: 5185.4199 - val_mae: 13.3574\n",
            "Epoch 500/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 157.9570 - mae: 8.4333 - val_loss: 4645.9355 - val_mae: 12.3725\n",
            "Epoch 501/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 135.2452 - mae: 8.1706 - val_loss: 3784.4910 - val_mae: 11.7289\n",
            "Epoch 502/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 134.1915 - mae: 8.0656 - val_loss: 5035.9004 - val_mae: 13.3198\n",
            "Epoch 503/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 134.3054 - mae: 8.0357 - val_loss: 4849.0752 - val_mae: 13.3845\n",
            "Epoch 504/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 132.2322 - mae: 8.3139 - val_loss: 3829.0364 - val_mae: 12.0082\n",
            "Epoch 505/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 132.9229 - mae: 8.1466 - val_loss: 1692.0902 - val_mae: 9.1658\n",
            "Epoch 506/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 143.7079 - mae: 8.2678 - val_loss: 871.5096 - val_mae: 7.9249\n",
            "Epoch 507/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 144.9153 - mae: 8.3688 - val_loss: 9304.7021 - val_mae: 17.1771\n",
            "Epoch 508/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 174.3752 - mae: 8.3662 - val_loss: 5470.0405 - val_mae: 13.5542\n",
            "Epoch 509/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 149.6487 - mae: 8.1238 - val_loss: 3316.6138 - val_mae: 11.7972\n",
            "Epoch 510/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 174.3720 - mae: 9.0949 - val_loss: 6522.1172 - val_mae: 14.3937\n",
            "Epoch 511/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 168.8036 - mae: 8.7967 - val_loss: 7488.3887 - val_mae: 15.7240\n",
            "Epoch 512/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 158.1047 - mae: 8.9048 - val_loss: 4137.2793 - val_mae: 12.0653\n",
            "Epoch 513/1000\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 142.2056 - mae: 8.1581 - val_loss: 3288.4629 - val_mae: 10.9033\n",
            "Epoch 514/1000\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 146.6055 - mae: 8.5088 - val_loss: 2700.2148 - val_mae: 10.2654\n",
            "Epoch 515/1000\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 158.2031 - mae: 8.1797 - val_loss: 1886.4509 - val_mae: 9.2211\n",
            "Epoch 516/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 155.8616 - mae: 8.2036 - val_loss: 7707.4473 - val_mae: 15.4642\n",
            "Epoch 517/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 187.7418 - mae: 8.7137 - val_loss: 152.2961 - val_mae: 5.5474\n",
            "Epoch 518/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 184.7207 - mae: 8.9882 - val_loss: 13464.5635 - val_mae: 19.8606\n",
            "Epoch 519/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 176.1971 - mae: 8.6497 - val_loss: 10536.8887 - val_mae: 17.5787\n",
            "Epoch 520/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 144.9781 - mae: 8.4903 - val_loss: 7672.4619 - val_mae: 15.4316\n",
            "Epoch 521/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 160.8229 - mae: 8.6186 - val_loss: 5349.5947 - val_mae: 13.4137\n",
            "Epoch 522/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 133.7267 - mae: 8.3350 - val_loss: 1411.6140 - val_mae: 9.3996\n",
            "Epoch 523/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 153.2534 - mae: 8.4996 - val_loss: 462.8645 - val_mae: 7.4690\n",
            "Epoch 524/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 127.6989 - mae: 8.1117 - val_loss: 5284.3872 - val_mae: 13.4773\n",
            "Epoch 525/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 138.9904 - mae: 8.3757 - val_loss: 4201.1572 - val_mae: 11.8601\n",
            "Epoch 526/1000\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 141.9782 - mae: 8.3803 - val_loss: 2239.7119 - val_mae: 9.9314\n",
            "Epoch 527/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 162.0652 - mae: 8.7180 - val_loss: 3215.4329 - val_mae: 10.9521\n",
            "Epoch 528/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 151.7421 - mae: 8.5011 - val_loss: 4549.0459 - val_mae: 12.4234\n",
            "Epoch 529/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 157.3997 - mae: 8.4212 - val_loss: 5176.6812 - val_mae: 13.7104\n",
            "Epoch 530/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 139.4867 - mae: 8.3989 - val_loss: 4689.2793 - val_mae: 12.8101\n",
            "Epoch 531/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 160.5888 - mae: 8.4668 - val_loss: 3965.0657 - val_mae: 11.8120\n",
            "Epoch 532/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 140.9141 - mae: 8.1121 - val_loss: 5386.4404 - val_mae: 13.4862\n",
            "Epoch 533/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 132.9386 - mae: 8.2931 - val_loss: 2865.8135 - val_mae: 10.6336\n",
            "Epoch 534/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 144.0427 - mae: 8.4707 - val_loss: 3089.6731 - val_mae: 11.3004\n",
            "Epoch 535/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 148.6513 - mae: 8.3173 - val_loss: 1042.8062 - val_mae: 8.1132\n",
            "Epoch 536/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 187.1458 - mae: 8.5917 - val_loss: 1764.1504 - val_mae: 9.3410\n",
            "Epoch 537/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 166.6069 - mae: 8.2419 - val_loss: 11235.1299 - val_mae: 18.0857\n",
            "Epoch 538/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 146.3671 - mae: 8.3034 - val_loss: 10085.1709 - val_mae: 17.1303\n",
            "Epoch 539/1000\n",
            "107/107 [==============================] - 4s 34ms/step - loss: 152.0954 - mae: 8.4493 - val_loss: 9199.2451 - val_mae: 16.6946\n",
            "Epoch 540/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 141.4195 - mae: 8.0661 - val_loss: 10303.0938 - val_mae: 17.3820\n",
            "Epoch 541/1000\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 153.3082 - mae: 8.2770 - val_loss: 10977.5381 - val_mae: 17.9993\n",
            "Epoch 542/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 130.7751 - mae: 8.1127 - val_loss: 8347.8535 - val_mae: 15.8675\n",
            "Epoch 543/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 130.1167 - mae: 8.0174 - val_loss: 8717.9082 - val_mae: 15.8894\n",
            "Epoch 544/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 147.5230 - mae: 8.4606 - val_loss: 11385.7744 - val_mae: 18.2168\n",
            "Epoch 545/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 171.6267 - mae: 8.7569 - val_loss: 13092.8398 - val_mae: 19.1775\n",
            "Epoch 546/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 185.8954 - mae: 8.6637 - val_loss: 15121.3320 - val_mae: 20.4474\n",
            "Epoch 547/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 161.9724 - mae: 8.6927 - val_loss: 4612.4185 - val_mae: 13.0048\n",
            "Epoch 548/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 165.2758 - mae: 8.6742 - val_loss: 8377.9229 - val_mae: 15.9875\n",
            "Epoch 549/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 143.9590 - mae: 8.5015 - val_loss: 6584.8335 - val_mae: 14.6995\n",
            "Epoch 550/1000\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 137.8724 - mae: 8.2858 - val_loss: 6932.3354 - val_mae: 14.7870\n",
            "Epoch 551/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 145.7232 - mae: 8.3457 - val_loss: 10073.8936 - val_mae: 16.9597\n",
            "Epoch 552/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 155.7651 - mae: 8.2397 - val_loss: 14738.4805 - val_mae: 19.8577\n",
            "Epoch 553/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 150.9431 - mae: 8.3453 - val_loss: 5099.7051 - val_mae: 13.4799\n",
            "Epoch 554/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 163.4272 - mae: 8.8655 - val_loss: 5357.9854 - val_mae: 14.4489\n",
            "Epoch 555/1000\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 188.1636 - mae: 8.8716 - val_loss: 3299.7637 - val_mae: 11.7119\n",
            "Epoch 556/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 161.2733 - mae: 8.6792 - val_loss: 9643.5225 - val_mae: 17.2504\n",
            "Epoch 557/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 150.7232 - mae: 8.5800 - val_loss: 7139.6279 - val_mae: 15.2153\n",
            "Epoch 558/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 153.0938 - mae: 8.4596 - val_loss: 6942.6992 - val_mae: 14.9614\n",
            "Epoch 559/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 155.5679 - mae: 8.4802 - val_loss: 9970.9844 - val_mae: 17.5752\n",
            "Epoch 560/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 181.4173 - mae: 8.8190 - val_loss: 3625.7234 - val_mae: 11.5460\n",
            "Epoch 561/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 146.7193 - mae: 8.4122 - val_loss: 6827.0059 - val_mae: 14.6758\n",
            "Epoch 562/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 138.1886 - mae: 8.4164 - val_loss: 4667.5454 - val_mae: 13.0307\n",
            "Epoch 563/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 157.8791 - mae: 8.7511 - val_loss: 4910.9751 - val_mae: 13.1865\n",
            "Epoch 564/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 150.7686 - mae: 8.5445 - val_loss: 4344.4829 - val_mae: 12.6558\n",
            "Epoch 565/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 128.2384 - mae: 8.1344 - val_loss: 5244.9121 - val_mae: 13.5981\n",
            "Epoch 566/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 143.1208 - mae: 8.2554 - val_loss: 5740.7217 - val_mae: 14.0244\n",
            "Epoch 567/1000\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 144.8524 - mae: 8.3660 - val_loss: 3754.4617 - val_mae: 11.9603\n",
            "Epoch 568/1000\n",
            "107/107 [==============================] - 7s 70ms/step - loss: 170.0554 - mae: 8.8977 - val_loss: 3982.3237 - val_mae: 11.8267\n",
            "Epoch 569/1000\n",
            "107/107 [==============================] - 6s 59ms/step - loss: 152.3254 - mae: 8.6473 - val_loss: 2742.7217 - val_mae: 10.6949\n",
            "Epoch 570/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 154.1548 - mae: 8.7046 - val_loss: 1547.6633 - val_mae: 8.6229\n",
            "Epoch 571/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 143.6994 - mae: 8.4139 - val_loss: 1273.4557 - val_mae: 8.4602\n",
            "Epoch 572/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 147.4000 - mae: 8.6402 - val_loss: 984.3614 - val_mae: 7.8943\n",
            "Epoch 573/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 170.9186 - mae: 8.3926 - val_loss: 3135.6060 - val_mae: 10.9740\n",
            "Epoch 574/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 159.2832 - mae: 8.4633 - val_loss: 3999.1340 - val_mae: 11.7141\n",
            "Epoch 575/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 130.6171 - mae: 8.2705 - val_loss: 3438.2605 - val_mae: 11.1358\n",
            "Epoch 576/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 148.0412 - mae: 8.5121 - val_loss: 3216.3169 - val_mae: 11.2370\n",
            "Epoch 577/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 147.6317 - mae: 8.3504 - val_loss: 2958.6958 - val_mae: 10.5730\n",
            "Epoch 578/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 151.7398 - mae: 8.2823 - val_loss: 10613.0557 - val_mae: 18.0867\n",
            "Epoch 579/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 156.3977 - mae: 8.6616 - val_loss: 4522.9790 - val_mae: 13.5595\n",
            "Epoch 580/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 171.9076 - mae: 8.6434 - val_loss: 553.8182 - val_mae: 7.8626\n",
            "Epoch 581/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 187.4658 - mae: 9.1477 - val_loss: 426.8535 - val_mae: 7.2002\n",
            "Epoch 582/1000\n",
            "107/107 [==============================] - 6s 54ms/step - loss: 164.8834 - mae: 8.3804 - val_loss: 445.2906 - val_mae: 6.8147\n",
            "Epoch 583/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 151.8366 - mae: 8.3152 - val_loss: 108.5668 - val_mae: 5.1408\n",
            "Epoch 584/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 128.8342 - mae: 8.1120 - val_loss: 263.4133 - val_mae: 5.9050\n",
            "Epoch 585/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 147.6056 - mae: 8.4095 - val_loss: 430.9481 - val_mae: 6.9105\n",
            "Epoch 586/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 156.1363 - mae: 8.6043 - val_loss: 1100.0304 - val_mae: 8.6974\n",
            "Epoch 587/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 150.1843 - mae: 8.5135 - val_loss: 820.3160 - val_mae: 8.0559\n",
            "Epoch 588/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 135.6216 - mae: 8.4895 - val_loss: 145.2177 - val_mae: 6.1301\n",
            "Epoch 589/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 171.6949 - mae: 8.8275 - val_loss: 1903.6526 - val_mae: 10.2002\n",
            "Epoch 590/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 177.8280 - mae: 8.8846 - val_loss: 2286.0840 - val_mae: 10.5083\n",
            "Epoch 591/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 136.2984 - mae: 8.3645 - val_loss: 1631.1436 - val_mae: 9.5210\n",
            "Epoch 592/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 147.0198 - mae: 8.2445 - val_loss: 386.4814 - val_mae: 6.5944\n",
            "Epoch 593/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 148.1664 - mae: 8.4485 - val_loss: 418.8087 - val_mae: 6.4732\n",
            "Epoch 594/1000\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 161.0749 - mae: 8.4686 - val_loss: 440.5730 - val_mae: 6.7922\n",
            "Epoch 595/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 162.5826 - mae: 8.3026 - val_loss: 387.0869 - val_mae: 6.6724\n",
            "Epoch 596/1000\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 145.2838 - mae: 8.3439 - val_loss: 226.6072 - val_mae: 5.8082\n",
            "Epoch 597/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 134.5373 - mae: 8.2214 - val_loss: 400.1396 - val_mae: 6.6873\n",
            "Epoch 598/1000\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 156.2540 - mae: 8.4866 - val_loss: 114.2317 - val_mae: 5.4460\n",
            "Epoch 599/1000\n",
            "107/107 [==============================] - 6s 57ms/step - loss: 172.2323 - mae: 8.5013 - val_loss: 124.4503 - val_mae: 5.5977\n",
            "Epoch 600/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 133.6021 - mae: 8.1534 - val_loss: 509.4126 - val_mae: 7.3241\n",
            "Epoch 601/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 148.6808 - mae: 8.4776 - val_loss: 1923.9810 - val_mae: 10.1270\n",
            "Epoch 602/1000\n",
            "107/107 [==============================] - 6s 58ms/step - loss: 159.3212 - mae: 8.3527 - val_loss: 1809.8542 - val_mae: 9.7957\n",
            "Epoch 603/1000\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 146.5851 - mae: 8.5073 - val_loss: 468.0239 - val_mae: 7.5167\n",
            "Epoch 604/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 162.7795 - mae: 8.2716 - val_loss: 1521.1896 - val_mae: 9.5241\n",
            "Epoch 605/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 149.4492 - mae: 8.3811 - val_loss: 1694.5979 - val_mae: 9.6844\n",
            "Epoch 606/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 142.1136 - mae: 8.0859 - val_loss: 2260.5330 - val_mae: 10.4456\n",
            "Epoch 607/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 145.6927 - mae: 8.2571 - val_loss: 1024.0903 - val_mae: 8.6018\n",
            "Epoch 608/1000\n",
            "107/107 [==============================] - 6s 59ms/step - loss: 165.0873 - mae: 8.4752 - val_loss: 62.4353 - val_mae: 4.5170\n",
            "Epoch 609/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 136.8363 - mae: 8.2267 - val_loss: 1978.1367 - val_mae: 9.6763\n",
            "Epoch 610/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 158.2834 - mae: 8.3740 - val_loss: 56.9433 - val_mae: 4.2344\n",
            "Epoch 611/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 141.6810 - mae: 8.5533 - val_loss: 1604.8196 - val_mae: 8.9390\n",
            "Epoch 612/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 149.4378 - mae: 8.2632 - val_loss: 443.1153 - val_mae: 6.1442\n",
            "Epoch 613/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 173.9813 - mae: 8.4838 - val_loss: 411.3600 - val_mae: 6.2675\n",
            "Epoch 614/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 151.3351 - mae: 8.4388 - val_loss: 362.5302 - val_mae: 6.6709\n",
            "Epoch 615/1000\n",
            "107/107 [==============================] - 8s 78ms/step - loss: 146.8819 - mae: 8.2466 - val_loss: 490.3586 - val_mae: 7.3365\n",
            "Epoch 616/1000\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 147.7462 - mae: 8.3275 - val_loss: 60.7206 - val_mae: 4.9014\n",
            "Epoch 617/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 158.5571 - mae: 8.4732 - val_loss: 442.8120 - val_mae: 6.8798\n",
            "Epoch 618/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 150.6720 - mae: 8.3534 - val_loss: 426.2037 - val_mae: 6.2927\n",
            "Epoch 619/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 149.5638 - mae: 8.5023 - val_loss: 55.8536 - val_mae: 4.4458\n",
            "Epoch 620/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 158.2475 - mae: 8.6403 - val_loss: 382.1979 - val_mae: 6.3099\n",
            "Epoch 621/1000\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 155.1902 - mae: 8.4211 - val_loss: 1962.5054 - val_mae: 9.6981\n",
            "Epoch 622/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 152.6490 - mae: 8.3861 - val_loss: 405.2380 - val_mae: 6.2967\n",
            "Epoch 623/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 141.9670 - mae: 8.1501 - val_loss: 318.0912 - val_mae: 6.0395\n",
            "Epoch 624/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 144.5802 - mae: 8.2541 - val_loss: 195.9030 - val_mae: 5.4911\n",
            "Epoch 625/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 141.5220 - mae: 8.3223 - val_loss: 382.4879 - val_mae: 6.6290\n",
            "Epoch 626/1000\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 154.3364 - mae: 8.2485 - val_loss: 948.4789 - val_mae: 7.8726\n",
            "Epoch 627/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 136.1287 - mae: 8.0931 - val_loss: 1097.0017 - val_mae: 8.4764\n",
            "Epoch 628/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 158.6552 - mae: 8.5347 - val_loss: 41.9105 - val_mae: 4.4245\n",
            "Epoch 629/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 143.5754 - mae: 8.3124 - val_loss: 579.1501 - val_mae: 6.8130\n",
            "Epoch 630/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 127.8278 - mae: 8.1312 - val_loss: 192.8842 - val_mae: 5.2760\n",
            "Epoch 631/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 132.6488 - mae: 8.2476 - val_loss: 261.9420 - val_mae: 5.8784\n",
            "Epoch 632/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 138.7227 - mae: 8.1381 - val_loss: 57.9293 - val_mae: 3.9144\n",
            "Epoch 633/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 130.0849 - mae: 7.9704 - val_loss: 88.7131 - val_mae: 4.5634\n",
            "Epoch 634/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 130.0050 - mae: 8.0481 - val_loss: 488.9991 - val_mae: 6.3788\n",
            "Epoch 635/1000\n",
            "107/107 [==============================] - 6s 57ms/step - loss: 142.4930 - mae: 8.3725 - val_loss: 247.3445 - val_mae: 5.8938\n",
            "Epoch 636/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 129.9215 - mae: 8.0178 - val_loss: 433.1679 - val_mae: 6.2037\n",
            "Epoch 637/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 148.8228 - mae: 8.0968 - val_loss: 408.0029 - val_mae: 6.5118\n",
            "Epoch 638/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 130.0242 - mae: 8.1710 - val_loss: 411.8727 - val_mae: 6.3622\n",
            "Epoch 639/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 173.9739 - mae: 8.5185 - val_loss: 357.0461 - val_mae: 6.1344\n",
            "Epoch 640/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 130.7823 - mae: 7.9497 - val_loss: 252.6289 - val_mae: 5.3529\n",
            "Epoch 641/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 144.8179 - mae: 8.1604 - val_loss: 128.5984 - val_mae: 4.8052\n",
            "Epoch 642/1000\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 135.8419 - mae: 8.0642 - val_loss: 28.4143 - val_mae: 3.6205\n",
            "Epoch 643/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 128.4371 - mae: 7.9115 - val_loss: 395.7413 - val_mae: 5.8755\n",
            "Epoch 644/1000\n",
            "107/107 [==============================] - 7s 63ms/step - loss: 133.8672 - mae: 7.9835 - val_loss: 427.0837 - val_mae: 6.1491\n",
            "Epoch 645/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 179.7184 - mae: 8.3223 - val_loss: 424.5608 - val_mae: 5.9639\n",
            "Epoch 646/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 134.9247 - mae: 8.2010 - val_loss: 28.5137 - val_mae: 3.6087\n",
            "Epoch 647/1000\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 129.6261 - mae: 8.1631 - val_loss: 1064.7567 - val_mae: 7.8601\n",
            "Epoch 648/1000\n",
            "107/107 [==============================] - 9s 88ms/step - loss: 142.5264 - mae: 8.0639 - val_loss: 219.6776 - val_mae: 5.4204\n",
            "Epoch 649/1000\n",
            "107/107 [==============================] - 5s 50ms/step - loss: 159.3168 - mae: 8.3526 - val_loss: 671.8054 - val_mae: 6.8833\n",
            "Epoch 650/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 152.5781 - mae: 8.3201 - val_loss: 1809.1333 - val_mae: 9.2786\n",
            "Epoch 651/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 160.6230 - mae: 8.0631 - val_loss: 1829.4513 - val_mae: 8.9096\n",
            "Epoch 652/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 148.9364 - mae: 8.4405 - val_loss: 3186.8621 - val_mae: 10.9956\n",
            "Epoch 653/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 139.6182 - mae: 8.1883 - val_loss: 640.8256 - val_mae: 6.6790\n",
            "Epoch 654/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 153.8778 - mae: 8.0444 - val_loss: 1052.5127 - val_mae: 8.2601\n",
            "Epoch 655/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 153.6759 - mae: 8.2550 - val_loss: 1410.9595 - val_mae: 8.8860\n",
            "Epoch 656/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 140.0803 - mae: 7.9994 - val_loss: 1479.5393 - val_mae: 8.7327\n",
            "Epoch 657/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 123.6618 - mae: 7.8906 - val_loss: 1752.9215 - val_mae: 9.5956\n",
            "Epoch 658/1000\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 134.7786 - mae: 8.0692 - val_loss: 650.6013 - val_mae: 7.4939\n",
            "Epoch 659/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 149.6410 - mae: 8.4118 - val_loss: 2832.8608 - val_mae: 11.7906\n",
            "Epoch 660/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 186.6622 - mae: 8.5414 - val_loss: 1670.8824 - val_mae: 9.7862\n",
            "Epoch 661/1000\n",
            "107/107 [==============================] - 7s 62ms/step - loss: 124.0815 - mae: 8.0580 - val_loss: 409.1400 - val_mae: 7.1397\n",
            "Epoch 662/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 145.5470 - mae: 8.1350 - val_loss: 8326.0645 - val_mae: 16.6280\n",
            "Epoch 663/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 174.5987 - mae: 8.3547 - val_loss: 4994.2358 - val_mae: 13.6561\n",
            "Epoch 664/1000\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 170.3759 - mae: 8.4778 - val_loss: 3678.0906 - val_mae: 12.0358\n",
            "Epoch 665/1000\n",
            "107/107 [==============================] - 7s 62ms/step - loss: 140.2530 - mae: 8.0338 - val_loss: 4619.7422 - val_mae: 13.4720\n",
            "Epoch 666/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 116.6003 - mae: 7.8855 - val_loss: 4754.7661 - val_mae: 13.7487\n",
            "Epoch 667/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 148.3013 - mae: 8.2272 - val_loss: 3414.2097 - val_mae: 12.0651\n",
            "Epoch 668/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 139.4164 - mae: 8.2923 - val_loss: 4185.6548 - val_mae: 12.6314\n",
            "Epoch 669/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 174.5954 - mae: 8.5493 - val_loss: 3644.7634 - val_mae: 11.6979\n",
            "Epoch 670/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 150.5474 - mae: 8.1985 - val_loss: 34.6555 - val_mae: 4.0673\n",
            "Epoch 671/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 131.6508 - mae: 7.9553 - val_loss: 48.8829 - val_mae: 4.7175\n",
            "Epoch 672/1000\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 130.1850 - mae: 8.1710 - val_loss: 494.7583 - val_mae: 6.7808\n",
            "Epoch 673/1000\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 157.7536 - mae: 8.4650 - val_loss: 2040.9174 - val_mae: 10.1317\n",
            "Epoch 674/1000\n",
            "107/107 [==============================] - 6s 56ms/step - loss: 152.3965 - mae: 8.1287 - val_loss: 1755.3411 - val_mae: 9.3384\n",
            "Epoch 675/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 160.3055 - mae: 8.0516 - val_loss: 60.8561 - val_mae: 4.4566\n",
            "Epoch 676/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 148.9307 - mae: 8.0497 - val_loss: 145.8103 - val_mae: 5.1947\n",
            "Epoch 677/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 136.7982 - mae: 8.1427 - val_loss: 9387.8145 - val_mae: 16.8063\n",
            "Epoch 678/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 157.0566 - mae: 8.2602 - val_loss: 9193.9219 - val_mae: 17.5878\n",
            "Epoch 679/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 141.9117 - mae: 8.4975 - val_loss: 12665.1885 - val_mae: 18.9419\n",
            "Epoch 680/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 158.5621 - mae: 8.3275 - val_loss: 12464.7090 - val_mae: 18.8747\n",
            "Epoch 681/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 204.8060 - mae: 8.6131 - val_loss: 11891.6621 - val_mae: 17.5673\n",
            "Epoch 682/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 128.3587 - mae: 7.8946 - val_loss: 8789.3193 - val_mae: 15.8291\n",
            "Epoch 683/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 136.3026 - mae: 8.1640 - val_loss: 7828.0737 - val_mae: 15.2566\n",
            "Epoch 684/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 157.4584 - mae: 8.3044 - val_loss: 7473.3916 - val_mae: 14.9184\n",
            "Epoch 685/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 140.6620 - mae: 8.0780 - val_loss: 2455.4211 - val_mae: 10.0967\n",
            "Epoch 686/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 167.2337 - mae: 8.7206 - val_loss: 749.8254 - val_mae: 7.4720\n",
            "Epoch 687/1000\n",
            "107/107 [==============================] - 4s 35ms/step - loss: 151.3592 - mae: 8.2901 - val_loss: 584.9431 - val_mae: 6.7536\n",
            "Epoch 688/1000\n",
            "107/107 [==============================] - 6s 57ms/step - loss: 153.9445 - mae: 8.3093 - val_loss: 190.0539 - val_mae: 5.4695\n",
            "Epoch 689/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 151.4885 - mae: 7.9240 - val_loss: 767.3895 - val_mae: 7.2564\n",
            "Epoch 690/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 147.6990 - mae: 8.1562 - val_loss: 4384.6763 - val_mae: 13.4716\n",
            "Epoch 691/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 173.1227 - mae: 8.7696 - val_loss: 8321.2695 - val_mae: 16.5200\n",
            "Epoch 692/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 146.1424 - mae: 8.3862 - val_loss: 3773.7190 - val_mae: 12.0906\n",
            "Epoch 693/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 137.9584 - mae: 8.2269 - val_loss: 2114.5383 - val_mae: 9.7125\n",
            "Epoch 694/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 173.3031 - mae: 8.4149 - val_loss: 3067.5342 - val_mae: 10.9483\n",
            "Epoch 695/1000\n",
            "107/107 [==============================] - 6s 56ms/step - loss: 156.7622 - mae: 8.2530 - val_loss: 432.8438 - val_mae: 6.5411\n",
            "Epoch 696/1000\n",
            "107/107 [==============================] - 7s 61ms/step - loss: 130.9598 - mae: 8.2800 - val_loss: 260.6493 - val_mae: 5.3265\n",
            "Epoch 697/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 147.8581 - mae: 8.4813 - val_loss: 366.4413 - val_mae: 6.1206\n",
            "Epoch 698/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 154.8948 - mae: 8.1969 - val_loss: 246.7640 - val_mae: 5.6847\n",
            "Epoch 699/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 146.9015 - mae: 8.4425 - val_loss: 42.6600 - val_mae: 4.1310\n",
            "Epoch 700/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 165.8476 - mae: 8.3445 - val_loss: 8978.1348 - val_mae: 16.3780\n",
            "Epoch 701/1000\n",
            "107/107 [==============================] - 6s 53ms/step - loss: 138.8326 - mae: 8.1690 - val_loss: 382.0948 - val_mae: 6.2259\n",
            "Epoch 702/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 168.9245 - mae: 8.4465 - val_loss: 440.3114 - val_mae: 6.8959\n",
            "Epoch 703/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 154.5027 - mae: 8.4372 - val_loss: 193.8177 - val_mae: 5.8553\n",
            "Epoch 704/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 174.7661 - mae: 8.5550 - val_loss: 8664.1533 - val_mae: 17.1186\n",
            "Epoch 705/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 171.1963 - mae: 8.5705 - val_loss: 7018.0649 - val_mae: 14.8063\n",
            "Epoch 706/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 146.0426 - mae: 8.5573 - val_loss: 2860.0090 - val_mae: 10.5693\n",
            "Epoch 707/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 145.7940 - mae: 8.1568 - val_loss: 2487.4614 - val_mae: 10.1107\n",
            "Epoch 708/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 126.4034 - mae: 7.9244 - val_loss: 2267.0605 - val_mae: 9.9474\n",
            "Epoch 709/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 143.7982 - mae: 8.3855 - val_loss: 1350.8027 - val_mae: 8.5283\n",
            "Epoch 710/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 138.0234 - mae: 8.0702 - val_loss: 2041.5413 - val_mae: 9.8869\n",
            "Epoch 711/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 139.0349 - mae: 7.9249 - val_loss: 962.0524 - val_mae: 7.3976\n",
            "Epoch 712/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 132.4963 - mae: 8.2862 - val_loss: 1392.8544 - val_mae: 8.4913\n",
            "Epoch 713/1000\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 154.6475 - mae: 8.0269 - val_loss: 1444.0964 - val_mae: 8.2747\n",
            "Epoch 714/1000\n",
            "107/107 [==============================] - 8s 76ms/step - loss: 152.7133 - mae: 8.2971 - val_loss: 351.2032 - val_mae: 5.8510\n",
            "Epoch 715/1000\n",
            "107/107 [==============================] - 6s 54ms/step - loss: 141.3897 - mae: 8.0961 - val_loss: 37.5818 - val_mae: 4.3757\n",
            "Epoch 716/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 165.4689 - mae: 8.6331 - val_loss: 313.0225 - val_mae: 6.3368\n",
            "Epoch 717/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 159.1185 - mae: 8.1944 - val_loss: 420.1760 - val_mae: 6.6653\n",
            "Epoch 718/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 177.9935 - mae: 8.5128 - val_loss: 955.8872 - val_mae: 7.6113\n",
            "Epoch 719/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 139.0806 - mae: 8.1576 - val_loss: 42.5236 - val_mae: 3.9918\n",
            "Epoch 720/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 177.9703 - mae: 8.5511 - val_loss: 421.1644 - val_mae: 5.9595\n",
            "Epoch 721/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 158.3187 - mae: 8.3073 - val_loss: 423.7712 - val_mae: 5.8810\n",
            "Epoch 722/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 140.4267 - mae: 8.3949 - val_loss: 379.3388 - val_mae: 6.2255\n",
            "Epoch 723/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 143.5371 - mae: 8.1740 - val_loss: 342.1313 - val_mae: 5.8053\n",
            "Epoch 724/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 164.2119 - mae: 8.2850 - val_loss: 426.7576 - val_mae: 5.8386\n",
            "Epoch 725/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 131.1122 - mae: 8.0359 - val_loss: 368.5490 - val_mae: 6.4918\n",
            "Epoch 726/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 158.8214 - mae: 8.4418 - val_loss: 384.0668 - val_mae: 6.2370\n",
            "Epoch 727/1000\n",
            "107/107 [==============================] - 5s 50ms/step - loss: 138.5971 - mae: 7.9603 - val_loss: 1885.3744 - val_mae: 10.0921\n",
            "Epoch 728/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 156.6517 - mae: 8.6668 - val_loss: 3374.8953 - val_mae: 11.6055\n",
            "Epoch 729/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 152.0804 - mae: 8.6482 - val_loss: 2654.8787 - val_mae: 11.1351\n",
            "Epoch 730/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 154.7886 - mae: 8.6509 - val_loss: 1963.4036 - val_mae: 9.7064\n",
            "Epoch 731/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 145.9691 - mae: 8.5524 - val_loss: 446.8072 - val_mae: 6.2775\n",
            "Epoch 732/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 168.2853 - mae: 8.2909 - val_loss: 424.9483 - val_mae: 6.4182\n",
            "Epoch 733/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 129.6530 - mae: 8.1157 - val_loss: 350.7983 - val_mae: 6.1172\n",
            "Epoch 734/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 139.2781 - mae: 8.4722 - val_loss: 435.3532 - val_mae: 6.5974\n",
            "Epoch 735/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 157.1827 - mae: 8.3275 - val_loss: 348.7846 - val_mae: 6.3862\n",
            "Epoch 736/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 146.4725 - mae: 8.2510 - val_loss: 228.4614 - val_mae: 5.4797\n",
            "Epoch 737/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 142.1399 - mae: 8.2821 - val_loss: 70.6860 - val_mae: 4.5027\n",
            "Epoch 738/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 152.2845 - mae: 8.1232 - val_loss: 129.4484 - val_mae: 5.1025\n",
            "Epoch 739/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 151.1647 - mae: 8.2425 - val_loss: 271.3221 - val_mae: 5.5757\n",
            "Epoch 740/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 154.4419 - mae: 8.4353 - val_loss: 204.0669 - val_mae: 5.3428\n",
            "Epoch 741/1000\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 157.3663 - mae: 8.2667 - val_loss: 219.1993 - val_mae: 5.3204\n",
            "Epoch 742/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 148.7878 - mae: 8.3426 - val_loss: 152.2588 - val_mae: 5.2761\n",
            "Epoch 743/1000\n",
            "107/107 [==============================] - 6s 58ms/step - loss: 142.0301 - mae: 8.1499 - val_loss: 115.1884 - val_mae: 4.9252\n",
            "Epoch 744/1000\n",
            "107/107 [==============================] - 6s 57ms/step - loss: 135.8991 - mae: 8.1309 - val_loss: 306.0537 - val_mae: 5.6634\n",
            "Epoch 745/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 142.9340 - mae: 8.0274 - val_loss: 6245.9048 - val_mae: 14.2908\n",
            "Epoch 746/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 191.7880 - mae: 8.7757 - val_loss: 1009.2250 - val_mae: 8.0041\n",
            "Epoch 747/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 133.1780 - mae: 8.2194 - val_loss: 979.4686 - val_mae: 8.2970\n",
            "Epoch 748/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 145.9671 - mae: 8.1678 - val_loss: 860.9001 - val_mae: 7.7251\n",
            "Epoch 749/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 164.9065 - mae: 8.4480 - val_loss: 180.1895 - val_mae: 5.8505\n",
            "Epoch 750/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 158.3035 - mae: 8.5271 - val_loss: 373.8428 - val_mae: 6.2272\n",
            "Epoch 751/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 144.6832 - mae: 8.2957 - val_loss: 389.9480 - val_mae: 6.3593\n",
            "Epoch 752/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 143.5404 - mae: 8.3929 - val_loss: 3218.4526 - val_mae: 11.4423\n",
            "Epoch 753/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 162.3731 - mae: 8.4787 - val_loss: 49.1007 - val_mae: 4.5269\n",
            "Epoch 754/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 171.6519 - mae: 8.4947 - val_loss: 46.1544 - val_mae: 4.4648\n",
            "Epoch 755/1000\n",
            "107/107 [==============================] - 6s 59ms/step - loss: 120.6899 - mae: 7.9373 - val_loss: 273.4105 - val_mae: 6.7047\n",
            "Epoch 756/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 126.1906 - mae: 8.1458 - val_loss: 286.1426 - val_mae: 6.2751\n",
            "Epoch 757/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 140.5458 - mae: 8.3022 - val_loss: 343.7820 - val_mae: 6.4090\n",
            "Epoch 758/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 126.8569 - mae: 8.1798 - val_loss: 295.1401 - val_mae: 6.0850\n",
            "Epoch 759/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 145.5022 - mae: 8.5811 - val_loss: 323.4287 - val_mae: 6.2944\n",
            "Epoch 760/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 128.9616 - mae: 8.1789 - val_loss: 297.4876 - val_mae: 5.8914\n",
            "Epoch 761/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 169.3598 - mae: 8.6020 - val_loss: 451.1511 - val_mae: 7.1634\n",
            "Epoch 762/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 202.8490 - mae: 8.9929 - val_loss: 461.3690 - val_mae: 6.4355\n",
            "Epoch 763/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 219.1310 - mae: 9.3404 - val_loss: 447.6080 - val_mae: 6.9112\n",
            "Epoch 764/1000\n",
            "107/107 [==============================] - 6s 58ms/step - loss: 183.8058 - mae: 8.8886 - val_loss: 445.9666 - val_mae: 6.7701\n",
            "Epoch 765/1000\n",
            "107/107 [==============================] - 7s 63ms/step - loss: 151.4925 - mae: 8.7053 - val_loss: 449.4654 - val_mae: 6.8026\n",
            "Epoch 766/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 182.3098 - mae: 8.7148 - val_loss: 438.6776 - val_mae: 6.4912\n",
            "Epoch 767/1000\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 139.7835 - mae: 8.4185 - val_loss: 437.5204 - val_mae: 6.3751\n",
            "Epoch 768/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 148.0313 - mae: 8.4526 - val_loss: 437.2242 - val_mae: 6.5634\n",
            "Epoch 769/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 163.4761 - mae: 8.6346 - val_loss: 443.5602 - val_mae: 6.6036\n",
            "Epoch 770/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 136.0179 - mae: 8.1294 - val_loss: 445.7494 - val_mae: 6.7162\n",
            "Epoch 771/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 139.0067 - mae: 8.2479 - val_loss: 435.8355 - val_mae: 6.4773\n",
            "Epoch 772/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 155.0382 - mae: 8.3783 - val_loss: 440.5807 - val_mae: 6.5516\n",
            "Epoch 773/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 142.0888 - mae: 8.2784 - val_loss: 419.2441 - val_mae: 6.1785\n",
            "Epoch 774/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 143.1453 - mae: 8.4503 - val_loss: 333.2554 - val_mae: 5.9697\n",
            "Epoch 775/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 169.3804 - mae: 8.3807 - val_loss: 357.9511 - val_mae: 6.3978\n",
            "Epoch 776/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 150.1356 - mae: 8.3833 - val_loss: 201.9810 - val_mae: 5.5888\n",
            "Epoch 777/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 143.8125 - mae: 8.4609 - val_loss: 281.6672 - val_mae: 5.7632\n",
            "Epoch 778/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 143.4921 - mae: 8.4975 - val_loss: 348.6136 - val_mae: 6.2317\n",
            "Epoch 779/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 128.1092 - mae: 8.0392 - val_loss: 371.2586 - val_mae: 6.4668\n",
            "Epoch 780/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 150.2426 - mae: 8.6237 - val_loss: 385.2027 - val_mae: 6.3665\n",
            "Epoch 781/1000\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 157.9766 - mae: 8.4824 - val_loss: 372.6474 - val_mae: 6.6196\n",
            "Epoch 782/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 129.7361 - mae: 8.1828 - val_loss: 379.0649 - val_mae: 6.9362\n",
            "Epoch 783/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 142.1857 - mae: 8.3305 - val_loss: 434.0882 - val_mae: 6.4617\n",
            "Epoch 784/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 137.7988 - mae: 8.2552 - val_loss: 396.8660 - val_mae: 5.9340\n",
            "Epoch 785/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 162.7305 - mae: 8.4333 - val_loss: 431.2164 - val_mae: 6.2425\n",
            "Epoch 786/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 140.0306 - mae: 8.3385 - val_loss: 63.6496 - val_mae: 4.7363\n",
            "Epoch 787/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 123.8992 - mae: 8.0193 - val_loss: 392.1833 - val_mae: 6.5299\n",
            "Epoch 788/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 140.2390 - mae: 8.1572 - val_loss: 797.2594 - val_mae: 7.5292\n",
            "Epoch 789/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 132.1413 - mae: 8.1422 - val_loss: 261.6767 - val_mae: 6.0626\n",
            "Epoch 790/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 145.6024 - mae: 8.1419 - val_loss: 701.8357 - val_mae: 7.3623\n",
            "Epoch 791/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 140.5417 - mae: 8.3262 - val_loss: 574.8815 - val_mae: 7.4465\n",
            "Epoch 792/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 136.8598 - mae: 8.0906 - val_loss: 103.4743 - val_mae: 5.0894\n",
            "Epoch 793/1000\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 137.6490 - mae: 8.2893 - val_loss: 284.0867 - val_mae: 6.2244\n",
            "Epoch 794/1000\n",
            "107/107 [==============================] - 8s 72ms/step - loss: 130.7045 - mae: 8.4282 - val_loss: 47.0642 - val_mae: 4.4111\n",
            "Epoch 795/1000\n",
            "107/107 [==============================] - 5s 50ms/step - loss: 134.0572 - mae: 8.1643 - val_loss: 310.1339 - val_mae: 6.8944\n",
            "Epoch 796/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 134.3652 - mae: 8.2753 - val_loss: 462.8989 - val_mae: 7.3380\n",
            "Epoch 797/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 140.2224 - mae: 8.1040 - val_loss: 3248.1067 - val_mae: 11.3470\n",
            "Epoch 798/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 183.3593 - mae: 8.7680 - val_loss: 1426.6381 - val_mae: 9.3677\n",
            "Epoch 799/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 157.7167 - mae: 8.8041 - val_loss: 1354.6849 - val_mae: 9.3327\n",
            "Epoch 800/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 145.1734 - mae: 8.3146 - val_loss: 1819.5530 - val_mae: 9.6343\n",
            "Epoch 801/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 162.3729 - mae: 8.5951 - val_loss: 1451.9958 - val_mae: 9.4392\n",
            "Epoch 802/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 155.2078 - mae: 8.3463 - val_loss: 1425.7346 - val_mae: 9.1012\n",
            "Epoch 803/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 151.3186 - mae: 8.2224 - val_loss: 2692.4976 - val_mae: 11.3260\n",
            "Epoch 804/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 149.3834 - mae: 8.4794 - val_loss: 3875.0828 - val_mae: 12.8222\n",
            "Epoch 805/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 153.2367 - mae: 8.2957 - val_loss: 4113.9326 - val_mae: 12.5112\n",
            "Epoch 806/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 147.1588 - mae: 8.5567 - val_loss: 2473.2939 - val_mae: 10.7207\n",
            "Epoch 807/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 135.7867 - mae: 8.1109 - val_loss: 2550.1064 - val_mae: 10.7107\n",
            "Epoch 808/1000\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 145.7919 - mae: 8.4540 - val_loss: 7501.8320 - val_mae: 15.6016\n",
            "Epoch 809/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 137.4345 - mae: 8.1121 - val_loss: 5466.9492 - val_mae: 13.7922\n",
            "Epoch 810/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 156.4056 - mae: 8.2847 - val_loss: 4615.3174 - val_mae: 13.0652\n",
            "Epoch 811/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 140.0159 - mae: 7.9068 - val_loss: 4183.3721 - val_mae: 12.2127\n",
            "Epoch 812/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 135.0636 - mae: 8.1097 - val_loss: 3386.0469 - val_mae: 11.5715\n",
            "Epoch 813/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 125.5367 - mae: 7.8900 - val_loss: 3410.5305 - val_mae: 11.5047\n",
            "Epoch 814/1000\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 155.6498 - mae: 8.5422 - val_loss: 1881.3708 - val_mae: 9.6904\n",
            "Epoch 815/1000\n",
            "107/107 [==============================] - 6s 57ms/step - loss: 131.8632 - mae: 8.0716 - val_loss: 2230.5042 - val_mae: 10.0857\n",
            "Epoch 816/1000\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 161.0521 - mae: 8.6287 - val_loss: 987.4062 - val_mae: 8.5100\n",
            "Epoch 817/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 138.3160 - mae: 8.3962 - val_loss: 1688.1229 - val_mae: 9.5624\n",
            "Epoch 818/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 117.6947 - mae: 8.0234 - val_loss: 1902.6198 - val_mae: 10.0200\n",
            "Epoch 819/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 152.2574 - mae: 8.4875 - val_loss: 1581.1366 - val_mae: 9.1922\n",
            "Epoch 820/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 130.2473 - mae: 8.0182 - val_loss: 1489.3469 - val_mae: 8.9021\n",
            "Epoch 821/1000\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 152.8715 - mae: 8.0597 - val_loss: 896.4465 - val_mae: 8.0292\n",
            "Epoch 822/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 125.0065 - mae: 8.3274 - val_loss: 1369.6183 - val_mae: 9.1578\n",
            "Epoch 823/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 140.5286 - mae: 8.1233 - val_loss: 72.0333 - val_mae: 4.6858\n",
            "Epoch 824/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 137.7946 - mae: 7.9586 - val_loss: 1100.0482 - val_mae: 8.6135\n",
            "Epoch 825/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 128.8621 - mae: 7.7294 - val_loss: 1360.4406 - val_mae: 8.3994\n",
            "Epoch 826/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 119.9338 - mae: 7.8216 - val_loss: 1688.0591 - val_mae: 8.8813\n",
            "Epoch 827/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 126.6524 - mae: 8.1691 - val_loss: 57.6049 - val_mae: 4.4386\n",
            "Epoch 828/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 146.3855 - mae: 8.1963 - val_loss: 337.8165 - val_mae: 6.1591\n",
            "Epoch 829/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 125.8557 - mae: 8.0713 - val_loss: 370.6725 - val_mae: 6.5832\n",
            "Epoch 830/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 130.8972 - mae: 8.2108 - val_loss: 1092.0289 - val_mae: 8.1281\n",
            "Epoch 831/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 126.7857 - mae: 8.0617 - val_loss: 36.5678 - val_mae: 4.1080\n",
            "Epoch 832/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 146.2686 - mae: 8.2663 - val_loss: 1273.6008 - val_mae: 8.5525\n",
            "Epoch 833/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 128.9157 - mae: 8.1270 - val_loss: 1729.4703 - val_mae: 9.7824\n",
            "Epoch 834/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 124.4270 - mae: 8.0656 - val_loss: 771.8396 - val_mae: 7.6714\n",
            "Epoch 835/1000\n",
            "107/107 [==============================] - 5s 51ms/step - loss: 144.4221 - mae: 8.1628 - val_loss: 345.5263 - val_mae: 6.3497\n",
            "Epoch 836/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 142.8769 - mae: 8.1522 - val_loss: 428.6574 - val_mae: 6.2728\n",
            "Epoch 837/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 162.8223 - mae: 8.3515 - val_loss: 446.9130 - val_mae: 6.6736\n",
            "Epoch 838/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 129.6745 - mae: 8.0585 - val_loss: 257.5219 - val_mae: 5.8119\n",
            "Epoch 839/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 132.9685 - mae: 8.0889 - val_loss: 51.7302 - val_mae: 4.4991\n",
            "Epoch 840/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 131.4538 - mae: 8.2381 - val_loss: 452.4922 - val_mae: 7.1423\n",
            "Epoch 841/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 126.5541 - mae: 7.7079 - val_loss: 110.5850 - val_mae: 5.2305\n",
            "Epoch 842/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 131.5246 - mae: 8.0650 - val_loss: 435.0601 - val_mae: 6.6302\n",
            "Epoch 843/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 138.7390 - mae: 8.1008 - val_loss: 384.6844 - val_mae: 6.4052\n",
            "Epoch 844/1000\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 147.9596 - mae: 7.9717 - val_loss: 311.7507 - val_mae: 6.5456\n",
            "Epoch 845/1000\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 148.5797 - mae: 8.1896 - val_loss: 3805.5078 - val_mae: 12.1850\n",
            "Epoch 846/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 135.0974 - mae: 7.9689 - val_loss: 3644.6736 - val_mae: 12.0364\n",
            "Epoch 847/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 127.6950 - mae: 8.0696 - val_loss: 327.6733 - val_mae: 6.4642\n",
            "Epoch 848/1000\n",
            "107/107 [==============================] - 6s 53ms/step - loss: 166.4928 - mae: 8.5492 - val_loss: 441.3867 - val_mae: 6.6037\n",
            "Epoch 849/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 148.1192 - mae: 8.1605 - val_loss: 447.5518 - val_mae: 6.7417\n",
            "Epoch 850/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 137.0971 - mae: 8.1691 - val_loss: 448.1248 - val_mae: 6.7306\n",
            "Epoch 851/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 163.4496 - mae: 8.4684 - val_loss: 428.8803 - val_mae: 7.0088\n",
            "Epoch 852/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 160.3090 - mae: 8.3585 - val_loss: 473.4202 - val_mae: 7.2880\n",
            "Epoch 853/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 149.0742 - mae: 8.3258 - val_loss: 476.0751 - val_mae: 7.4076\n",
            "Epoch 854/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 144.2428 - mae: 8.2031 - val_loss: 438.2119 - val_mae: 6.8964\n",
            "Epoch 855/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 126.1162 - mae: 7.8598 - val_loss: 437.2598 - val_mae: 6.5999\n",
            "Epoch 856/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 137.8537 - mae: 7.9820 - val_loss: 442.6590 - val_mae: 6.9034\n",
            "Epoch 857/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 120.2751 - mae: 7.8530 - val_loss: 387.4720 - val_mae: 6.9566\n",
            "Epoch 858/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 138.0880 - mae: 8.0573 - val_loss: 428.6994 - val_mae: 6.5259\n",
            "Epoch 859/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 143.8996 - mae: 8.0954 - val_loss: 418.1755 - val_mae: 6.3677\n",
            "Epoch 860/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 154.5462 - mae: 8.3152 - val_loss: 418.8846 - val_mae: 6.1605\n",
            "Epoch 861/1000\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 151.2564 - mae: 8.1311 - val_loss: 381.8637 - val_mae: 6.0783\n",
            "Epoch 862/1000\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 156.6637 - mae: 8.3788 - val_loss: 292.8227 - val_mae: 6.1192\n",
            "Epoch 863/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 143.5048 - mae: 7.9210 - val_loss: 118.0293 - val_mae: 5.3803\n",
            "Epoch 864/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 124.7435 - mae: 8.0187 - val_loss: 65.0615 - val_mae: 4.7351\n",
            "Epoch 865/1000\n",
            "107/107 [==============================] - 6s 53ms/step - loss: 133.5876 - mae: 8.0483 - val_loss: 89.4654 - val_mae: 5.1536\n",
            "Epoch 866/1000\n",
            "107/107 [==============================] - 6s 57ms/step - loss: 128.3953 - mae: 7.9775 - val_loss: 51.3448 - val_mae: 4.5717\n",
            "Epoch 867/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 143.6855 - mae: 8.3034 - val_loss: 73.7219 - val_mae: 5.0660\n",
            "Epoch 868/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 126.2939 - mae: 8.1522 - val_loss: 87.6942 - val_mae: 5.1651\n",
            "Epoch 869/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 146.9409 - mae: 8.4454 - val_loss: 186.3400 - val_mae: 5.9111\n",
            "Epoch 870/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 150.4490 - mae: 8.6342 - val_loss: 415.8303 - val_mae: 7.3496\n",
            "Epoch 871/1000\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 148.1694 - mae: 8.5077 - val_loss: 425.7676 - val_mae: 7.0663\n",
            "Epoch 872/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 129.2936 - mae: 8.1287 - val_loss: 230.4317 - val_mae: 6.3132\n",
            "Epoch 873/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 139.3280 - mae: 8.3876 - val_loss: 485.8246 - val_mae: 7.6568\n",
            "Epoch 874/1000\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 144.3983 - mae: 8.0938 - val_loss: 84.7364 - val_mae: 4.9764\n",
            "Epoch 875/1000\n",
            "107/107 [==============================] - 6s 53ms/step - loss: 127.5914 - mae: 8.0146 - val_loss: 146.0663 - val_mae: 5.8899\n",
            "Epoch 876/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 130.2822 - mae: 8.0911 - val_loss: 96.7708 - val_mae: 5.1370\n",
            "Epoch 877/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 158.5229 - mae: 8.2738 - val_loss: 260.9330 - val_mae: 6.5161\n",
            "Epoch 878/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 125.5031 - mae: 7.8499 - val_loss: 266.4524 - val_mae: 6.4804\n",
            "Epoch 879/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 154.9896 - mae: 8.4780 - val_loss: 456.2400 - val_mae: 6.7952\n",
            "Epoch 880/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 127.9726 - mae: 8.1072 - val_loss: 461.0602 - val_mae: 7.3252\n",
            "Epoch 881/1000\n",
            "107/107 [==============================] - 4s 36ms/step - loss: 153.0628 - mae: 8.0658 - val_loss: 447.9425 - val_mae: 6.9397\n",
            "Epoch 882/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 152.3932 - mae: 8.6471 - val_loss: 459.0883 - val_mae: 7.2143\n",
            "Epoch 883/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 126.4797 - mae: 8.0607 - val_loss: 479.3656 - val_mae: 7.4894\n",
            "Epoch 884/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 170.8417 - mae: 8.1316 - val_loss: 475.5303 - val_mae: 7.2971\n",
            "Epoch 885/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 159.4684 - mae: 8.5232 - val_loss: 457.4075 - val_mae: 7.1528\n",
            "Epoch 886/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 140.8525 - mae: 8.1130 - val_loss: 422.1180 - val_mae: 7.1725\n",
            "Epoch 887/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 139.0229 - mae: 7.9427 - val_loss: 350.6524 - val_mae: 6.2372\n",
            "Epoch 888/1000\n",
            "107/107 [==============================] - 6s 53ms/step - loss: 138.8004 - mae: 7.8863 - val_loss: 384.0049 - val_mae: 6.3451\n",
            "Epoch 889/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 153.9479 - mae: 8.0937 - val_loss: 441.4218 - val_mae: 6.6960\n",
            "Epoch 890/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 136.2236 - mae: 7.9961 - val_loss: 452.2040 - val_mae: 6.8673\n",
            "Epoch 891/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 166.4956 - mae: 8.0070 - val_loss: 448.5222 - val_mae: 6.7701\n",
            "Epoch 892/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 134.7203 - mae: 8.2508 - val_loss: 1049.1761 - val_mae: 9.0144\n",
            "Epoch 893/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 210.9549 - mae: 9.0987 - val_loss: 956.6134 - val_mae: 9.1515\n",
            "Epoch 894/1000\n",
            "107/107 [==============================] - 8s 71ms/step - loss: 127.8933 - mae: 8.2501 - val_loss: 817.8917 - val_mae: 8.6092\n",
            "Epoch 895/1000\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 146.4423 - mae: 8.3493 - val_loss: 911.4030 - val_mae: 8.9492\n",
            "Epoch 896/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 175.9468 - mae: 8.6100 - val_loss: 845.8783 - val_mae: 9.1630\n",
            "Epoch 897/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 173.1323 - mae: 9.0048 - val_loss: 599.6178 - val_mae: 9.0744\n",
            "Epoch 898/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 157.0704 - mae: 8.7086 - val_loss: 423.9212 - val_mae: 8.1749\n",
            "Epoch 899/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 151.6906 - mae: 8.5460 - val_loss: 160.5300 - val_mae: 6.3642\n",
            "Epoch 900/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 187.1857 - mae: 9.0155 - val_loss: 458.9280 - val_mae: 7.9215\n",
            "Epoch 901/1000\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 139.3845 - mae: 8.4736 - val_loss: 441.5937 - val_mae: 7.4361\n",
            "Epoch 902/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 169.3195 - mae: 8.8396 - val_loss: 452.9157 - val_mae: 7.7764\n",
            "Epoch 903/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 144.3066 - mae: 8.7085 - val_loss: 431.0429 - val_mae: 7.8182\n",
            "Epoch 904/1000\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 142.5573 - mae: 8.2972 - val_loss: 458.2952 - val_mae: 7.8291\n",
            "Epoch 905/1000\n",
            "107/107 [==============================] - 6s 54ms/step - loss: 147.8892 - mae: 8.4867 - val_loss: 434.5894 - val_mae: 7.7362\n",
            "Epoch 906/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 136.6850 - mae: 8.2467 - val_loss: 449.7896 - val_mae: 7.4847\n",
            "Epoch 907/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 143.6819 - mae: 8.2645 - val_loss: 381.5586 - val_mae: 7.2525\n",
            "Epoch 908/1000\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 141.9764 - mae: 8.4786 - val_loss: 425.1428 - val_mae: 7.2724\n",
            "Epoch 909/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 151.7472 - mae: 8.2401 - val_loss: 417.5932 - val_mae: 7.3876\n",
            "Epoch 910/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 147.0523 - mae: 8.5474 - val_loss: 372.4853 - val_mae: 7.0673\n",
            "Epoch 911/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 154.7432 - mae: 8.3908 - val_loss: 386.3047 - val_mae: 7.2032\n",
            "Epoch 912/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 158.6244 - mae: 8.3473 - val_loss: 453.3347 - val_mae: 7.1301\n",
            "Epoch 913/1000\n",
            "107/107 [==============================] - 8s 73ms/step - loss: 168.3594 - mae: 8.7319 - val_loss: 447.5779 - val_mae: 7.2044\n",
            "Epoch 914/1000\n",
            "107/107 [==============================] - 8s 77ms/step - loss: 132.2450 - mae: 8.3123 - val_loss: 420.5237 - val_mae: 7.0087\n",
            "Epoch 915/1000\n",
            "107/107 [==============================] - 6s 56ms/step - loss: 156.2189 - mae: 8.6250 - val_loss: 418.2705 - val_mae: 7.1163\n",
            "Epoch 916/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 138.0530 - mae: 8.3868 - val_loss: 401.8152 - val_mae: 6.9595\n",
            "Epoch 917/1000\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 175.9724 - mae: 8.6899 - val_loss: 461.4963 - val_mae: 7.6233\n",
            "Epoch 918/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 134.7351 - mae: 8.5130 - val_loss: 482.8689 - val_mae: 7.9259\n",
            "Epoch 919/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 145.8097 - mae: 8.4915 - val_loss: 466.2655 - val_mae: 7.5234\n",
            "Epoch 920/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 141.0518 - mae: 8.4590 - val_loss: 458.5288 - val_mae: 7.4731\n",
            "Epoch 921/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 145.4575 - mae: 8.5378 - val_loss: 454.8260 - val_mae: 7.2264\n",
            "Epoch 922/1000\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 136.6834 - mae: 8.2352 - val_loss: 471.8094 - val_mae: 7.4938\n",
            "Epoch 923/1000\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 148.3189 - mae: 8.4962 - val_loss: 467.0047 - val_mae: 7.3744\n",
            "Epoch 924/1000\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 142.2810 - mae: 8.3303 - val_loss: 454.7808 - val_mae: 7.1475\n",
            "Epoch 925/1000\n",
            "107/107 [==============================] - 7s 65ms/step - loss: 142.2690 - mae: 8.1760 - val_loss: 461.8378 - val_mae: 7.2552\n",
            "Epoch 926/1000\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 182.7834 - mae: 9.0005 - val_loss: 483.9628 - val_mae: 8.4869\n",
            "Epoch 927/1000\n",
            "107/107 [==============================] - 6s 55ms/step - loss: 272.8853 - mae: 9.7513 - val_loss: 501.3817 - val_mae: 8.2707\n",
            "Epoch 928/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 214.6412 - mae: 9.3248 - val_loss: 486.6123 - val_mae: 7.8393\n",
            "Epoch 929/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 160.4168 - mae: 8.9043 - val_loss: 485.1845 - val_mae: 7.6463\n",
            "Epoch 930/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 173.2591 - mae: 8.9289 - val_loss: 475.0763 - val_mae: 7.4528\n",
            "Epoch 931/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 221.8479 - mae: 9.1303 - val_loss: 490.3495 - val_mae: 7.6012\n",
            "Epoch 932/1000\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 175.1409 - mae: 8.8704 - val_loss: 449.9105 - val_mae: 7.1925\n",
            "Epoch 933/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 185.7059 - mae: 8.7868 - val_loss: 449.7219 - val_mae: 7.0720\n",
            "Epoch 934/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 170.6535 - mae: 8.7262 - val_loss: 453.0232 - val_mae: 7.3944\n",
            "Epoch 935/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 164.3624 - mae: 8.7060 - val_loss: 456.5969 - val_mae: 7.4771\n",
            "Epoch 936/1000\n",
            "107/107 [==============================] - 5s 50ms/step - loss: 200.4402 - mae: 8.9594 - val_loss: 460.0962 - val_mae: 7.6586\n",
            "Epoch 937/1000\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 155.4911 - mae: 8.4829 - val_loss: 460.3338 - val_mae: 7.4952\n",
            "Epoch 938/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 159.2235 - mae: 8.5290 - val_loss: 444.5773 - val_mae: 7.0073\n",
            "Epoch 939/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 150.7903 - mae: 8.4669 - val_loss: 450.2147 - val_mae: 7.0964\n",
            "Epoch 940/1000\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 144.9646 - mae: 8.3719 - val_loss: 445.1873 - val_mae: 6.9884\n",
            "Epoch 941/1000\n",
            "107/107 [==============================] - 6s 59ms/step - loss: 157.0666 - mae: 8.5685 - val_loss: 449.6347 - val_mae: 6.9934\n",
            "Epoch 942/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 184.2552 - mae: 8.6355 - val_loss: 447.1808 - val_mae: 6.9919\n",
            "Epoch 943/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 165.0972 - mae: 8.6021 - val_loss: 464.2927 - val_mae: 7.1011\n",
            "Epoch 944/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 148.7125 - mae: 8.4895 - val_loss: 506.2709 - val_mae: 7.2241\n",
            "Epoch 945/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 204.6168 - mae: 9.0193 - val_loss: 456.3452 - val_mae: 7.1555\n",
            "Epoch 946/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 167.6875 - mae: 8.6717 - val_loss: 455.0502 - val_mae: 7.1323\n",
            "Epoch 947/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 127.1381 - mae: 8.1561 - val_loss: 452.2365 - val_mae: 7.1336\n",
            "Epoch 948/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 137.1760 - mae: 8.4113 - val_loss: 444.8827 - val_mae: 6.9188\n",
            "Epoch 949/1000\n",
            "107/107 [==============================] - 6s 55ms/step - loss: 147.8170 - mae: 8.4138 - val_loss: 445.4733 - val_mae: 6.9383\n",
            "Epoch 950/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 143.6510 - mae: 8.6116 - val_loss: 469.0612 - val_mae: 7.4576\n",
            "Epoch 951/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 151.5452 - mae: 8.6104 - val_loss: 459.7517 - val_mae: 7.2664\n",
            "Epoch 952/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 168.4779 - mae: 8.7323 - val_loss: 501.5809 - val_mae: 7.1009\n",
            "Epoch 953/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 128.4671 - mae: 8.0532 - val_loss: 534.0371 - val_mae: 7.1684\n",
            "Epoch 954/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 147.2160 - mae: 8.2043 - val_loss: 464.7007 - val_mae: 7.0747\n",
            "Epoch 955/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 142.3867 - mae: 8.3199 - val_loss: 473.5858 - val_mae: 7.0302\n",
            "Epoch 956/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 146.6832 - mae: 8.2474 - val_loss: 440.5747 - val_mae: 6.6613\n",
            "Epoch 957/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 149.2313 - mae: 8.4683 - val_loss: 446.4806 - val_mae: 6.8543\n",
            "Epoch 958/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 141.6210 - mae: 8.2011 - val_loss: 453.1336 - val_mae: 6.9309\n",
            "Epoch 959/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 134.9240 - mae: 8.2542 - val_loss: 453.1614 - val_mae: 6.8519\n",
            "Epoch 960/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 145.9749 - mae: 8.2049 - val_loss: 444.1478 - val_mae: 6.7857\n",
            "Epoch 961/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 144.5997 - mae: 7.9445 - val_loss: 461.9816 - val_mae: 7.6350\n",
            "Epoch 962/1000\n",
            "107/107 [==============================] - 8s 72ms/step - loss: 154.9030 - mae: 8.3418 - val_loss: 442.5394 - val_mae: 6.6938\n",
            "Epoch 963/1000\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 157.3445 - mae: 8.4345 - val_loss: 453.0662 - val_mae: 6.8052\n",
            "Epoch 964/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 125.7092 - mae: 8.0819 - val_loss: 461.6918 - val_mae: 6.7636\n",
            "Epoch 965/1000\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 129.9603 - mae: 8.1861 - val_loss: 594.8701 - val_mae: 7.1740\n",
            "Epoch 966/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 117.2446 - mae: 7.8914 - val_loss: 492.2604 - val_mae: 6.8695\n",
            "Epoch 967/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 131.1049 - mae: 8.0529 - val_loss: 461.5889 - val_mae: 6.9053\n",
            "Epoch 968/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 143.1358 - mae: 8.1172 - val_loss: 481.5764 - val_mae: 6.9963\n",
            "Epoch 969/1000\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 131.2020 - mae: 8.0145 - val_loss: 504.6966 - val_mae: 7.1265\n",
            "Epoch 970/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 134.9326 - mae: 7.9386 - val_loss: 525.6353 - val_mae: 7.2523\n",
            "Epoch 971/1000\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 125.7090 - mae: 7.8003 - val_loss: 507.0230 - val_mae: 7.1780\n",
            "Epoch 972/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 126.5119 - mae: 8.0813 - val_loss: 501.8332 - val_mae: 6.9548\n",
            "Epoch 973/1000\n",
            "107/107 [==============================] - 4s 37ms/step - loss: 131.2847 - mae: 8.0163 - val_loss: 497.0645 - val_mae: 7.0868\n",
            "Epoch 974/1000\n",
            "107/107 [==============================] - 5s 51ms/step - loss: 133.4698 - mae: 8.3868 - val_loss: 577.8763 - val_mae: 7.3040\n",
            "Epoch 975/1000\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 137.6918 - mae: 8.0589 - val_loss: 618.5306 - val_mae: 7.3174\n",
            "Epoch 976/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 141.9539 - mae: 7.9987 - val_loss: 516.0188 - val_mae: 6.7734\n",
            "Epoch 977/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 131.2526 - mae: 8.0702 - val_loss: 501.6254 - val_mae: 6.5510\n",
            "Epoch 978/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 120.0396 - mae: 7.8331 - val_loss: 514.8401 - val_mae: 6.7945\n",
            "Epoch 979/1000\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 131.2300 - mae: 7.7536 - val_loss: 503.4327 - val_mae: 6.7393\n",
            "Epoch 980/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 126.7200 - mae: 7.7261 - val_loss: 498.4182 - val_mae: 6.7235\n",
            "Epoch 981/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 125.1134 - mae: 8.0914 - val_loss: 463.4484 - val_mae: 6.5920\n",
            "Epoch 982/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 120.5255 - mae: 8.0372 - val_loss: 516.7808 - val_mae: 6.6037\n",
            "Epoch 983/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 124.8665 - mae: 7.8875 - val_loss: 467.4312 - val_mae: 6.3965\n",
            "Epoch 984/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 149.4689 - mae: 8.4543 - val_loss: 486.4562 - val_mae: 6.8652\n",
            "Epoch 985/1000\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 125.5888 - mae: 8.1598 - val_loss: 500.7322 - val_mae: 7.0602\n",
            "Epoch 986/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 129.2760 - mae: 7.8797 - val_loss: 468.4644 - val_mae: 6.7411\n",
            "Epoch 987/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 133.4681 - mae: 8.0564 - val_loss: 491.4193 - val_mae: 6.9993\n",
            "Epoch 988/1000\n",
            "107/107 [==============================] - 6s 55ms/step - loss: 130.5928 - mae: 7.9755 - val_loss: 509.0016 - val_mae: 6.6432\n",
            "Epoch 989/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 160.8481 - mae: 8.2248 - val_loss: 510.5741 - val_mae: 6.8067\n",
            "Epoch 990/1000\n",
            "107/107 [==============================] - 6s 56ms/step - loss: 151.4040 - mae: 8.3601 - val_loss: 493.7503 - val_mae: 6.5072\n",
            "Epoch 991/1000\n",
            "107/107 [==============================] - 7s 63ms/step - loss: 132.5361 - mae: 8.0782 - val_loss: 525.2251 - val_mae: 8.2178\n",
            "Epoch 992/1000\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 139.9539 - mae: 8.3493 - val_loss: 443.5567 - val_mae: 6.8901\n",
            "Epoch 993/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 139.6916 - mae: 8.3168 - val_loss: 447.3818 - val_mae: 6.3447\n",
            "Epoch 994/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 141.8228 - mae: 8.1851 - val_loss: 449.3997 - val_mae: 6.4873\n",
            "Epoch 995/1000\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 132.8139 - mae: 8.4407 - val_loss: 452.7498 - val_mae: 7.0691\n",
            "Epoch 996/1000\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 124.8115 - mae: 7.8696 - val_loss: 428.5788 - val_mae: 6.3483\n",
            "Epoch 997/1000\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 134.8988 - mae: 8.0197 - val_loss: 431.9787 - val_mae: 6.3190\n",
            "Epoch 998/1000\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 122.9944 - mae: 8.0401 - val_loss: 445.6695 - val_mae: 6.2357\n",
            "Epoch 999/1000\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 189.5956 - mae: 8.5778 - val_loss: 460.7960 - val_mae: 6.8447\n",
            "Epoch 1000/1000\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 154.0468 - mae: 8.5693 - val_loss: 452.9838 - val_mae: 6.7789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## R^2 score"
      ],
      "metadata": {
        "id": "7Aqv3RMxseN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m_best_11 = keras.models.load_model('best-model_regress_1208_8.h5')"
      ],
      "metadata": {
        "id": "m0IKpHQnyP4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2 = r2_score(y_test_lr.values, m_best_11.predict(x_test_scaled_lr))\n",
        "print(r2)"
      ],
      "metadata": {
        "id": "mACdwlkZyeh6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e97459d-87ac-488d-94ac-e5c901974954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 2s 19ms/step\n",
            "0.9695398824387353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MAE, MSE, RMSE"
      ],
      "metadata": {
        "id": "dwZD6Kc1sjEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = m_best_11.predict(x_test_scaled_lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "javoIZv07n-j",
        "outputId": "4da087d5-18d2-47c8-f6a7-3fd8783b19cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34/34 [==============================] - 0s 12ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mae = mean_absolute_error(y_test_lr.values, y_pred)\n",
        "mse = mean_squared_error(y_test_lr.values, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test_lr.values, y_pred))\n",
        "\n",
        "print('MAE: {0:.2f}'.format(mae))\n",
        "print('MSE: {0:.2f}'.format(mse))\n",
        "print('RMSE: {0:.2f}'.format(rmse)) "
      ],
      "metadata": {
        "id": "otdX2VWvwpWC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa7e3619-38ea-4e19-96fc-1b3d989b0fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 3.60\n",
            "MSE: 26.59\n",
            "RMSE: 5.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## loss plot"
      ],
      "metadata": {
        "id": "onzf8e5KspP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist_1208_3.history['loss'])"
      ],
      "metadata": {
        "id": "0kdlmxemw3_Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "8add6834-6988-4302-c0ac-d50517376a98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbdfb4f8e20>]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(hist_1208_3.history['val_loss'])"
      ],
      "metadata": {
        "id": "mO2SCLc9xGpD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "c8df83f0-0fa9-4233-97d8-d4994ad4ee4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fbdfb6472e0>]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}